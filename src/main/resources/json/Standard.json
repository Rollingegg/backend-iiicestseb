{"title": "Statistical Errors in Software Engineering Experiments: A Preliminary Literature Review", "authors": [{"name": "Rolando P. Reyes Ch.", "affiliation": "Univ. Politec. de Madrid, Madrid, Spain", "firstName": "Rolando P.", "lastName": "Reyes Ch."}, {"name": "Oscar Dieste", "affiliation": "Univ. Politec. de Madrid, Madrid, Spain", "firstName": "Oscar", "lastName": "Dieste"}, {"name": "Efra\u00edn R. Fonseca C.", "affiliation": "", "firstName": "Efra\u00edn R.", "lastName": "Fonseca C."}, {"name": "Natalia Juristo", "affiliation": "Univ. Politec. de Madrid, Madrid, Spain", "firstName": "Natalia", "lastName": "Juristo"}], "abstract": "Background: Statistical concepts and techniques are often applied incorrectly, even in mature disciplines such as medicine or psychology. Surprisingly, there are very few works that study statistical problems in software engineering (SE). Aim: Assess the existence of statistical errors in SE experiments. Method: Compile the most common statistical errors in experimental disciplines. Survey experiments published in ICSE to assess whether errors occur in high quality SE publications. Results: The same errors as identified in others disciplines were found in ICSE experiments, where 30 of the reviewed papers included several error types such as: a) missing statistical hypotheses, b) missing sample size calculation, c) failure to assess statistical test assumptions, and d) uncorrected multiple testing. This rather large error rate is greater for research papers where experiments are confined to the validation section. The origin of the errors can be traced back to: a) researchers not having sufficient statistical training, and b) a profusion of exploratory research. Conclusions: This paper provides preliminary evidence that SE research suffers from the same statistical problems as other experimental disciplines. However, the SE community appears to be unaware of any shortcomings in its experiments, whereas other disciplines work hard to avoid these threats. Further research is necessary to find the underlying causes and set up corrective measures, but there are some potentially effective actions and are a priori easy to implement: a) improve the statistical training of SE researchers, and b) enforce quality assessment and reporting guidelines in SE publications.", "keywords": [{"type": "IEEE Keywords", "kwd": ["Software engineering", "Bibliographies", "Training", "Guidelines", "Error analysis", "Back"]}, {"type": "INSPEC: Controlled Indexing", "kwd": ["psychology", "research and development", "software engineering", "statistical testing"]}, {"type": "INSPEC: Non-Controlled Indexing", "kwd": ["software engineering experiments", "SE experiments", "high quality SE publications", "ICSE experiments", "statistical hypotheses", "statistical test assumptions", "SE community", "SE researchers", "quality assessment", "statistical errors", "statistical training", "SE research"]}, {"type": "Author Keywords ", "kwd": ["Literature review", "Survey", "Prevalence", "Statistical errors"]}], "publication": "2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)", "doi": "10.1145/3180155.3180161", "ref": [], "pdfLink": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453201", "articleId": "8453201", "startPage": "1195", "endPage": "1206", "pubLink": "https://ieeexplore.ieee.org/xpl/conhome/8452039/proceeding", "issueLink": "https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8453044", "publisher": "IEEE", "confLoc": "Gothenburg, Sweden", "chronDate": "May 27 2018-June 3 2018", "metrics": {"citationCountPaper": 0, "citationCountPatent": 0, "totalDownloads": 84}}
{"title": "3rd FME Workshop on Formal Methods in Software Engineering (FormaliSE 2015)", "authors": [{"name": "Stefania Gnesi", "affiliation": "", "firstName": "Stefania", "lastName": "Gnesi", "id": "37282428500"}, {"name": "Nico Plat", "affiliation": "", "firstName": "Nico", "lastName": "Plat", "id": "37622184000"}], "abstract": "Despite their significant advantages, formal methods are not widely used in industrial software development. Following the successful workshops we organized at ICSE 2103 in San Francisco, and ICSE 2014 in Hyderabad, we organize a third edition of the FormaliSE workshop with the main goal to promote the integration between the formal methods and the software engineering communities.", "keywords": [{"type": "IEEE Keywords", "kwd": ["Software", "Conferences", "Software engineering", "Security", "Committees", "Industries", "Collaboration"]}, {"type": "Author Keywords ", "kwd": ["Formal methods", "Software engineering"]}], "publication": "2015 IEEE/ACM 37th IEEE International Conference on Software Engineering", "doi": "10.1109/ICSE.2015.313", "ref": [], "pdfLink": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203136", "articleId": "7203136", "startPage": "977", "endPage": "978", "pubLink": "https://ieeexplore.ieee.org/xpl/conhome/7174815/proceeding", "issueLink": "https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7202933", "publisher": "IEEE", "confLoc": "Florence, Italy", "chronDate": "16-24 May 2015", "metrics": {"citationCountPaper": 0, "citationCountPatent": 0, "totalDownloads": 92}}
{"title": "A Novel Neural Source Code Representation Based on Abstract Syntax Tree", "authors": [{"name": "Jian Zhang", "affiliation": "Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China", "firstName": "Jian", "lastName": "Zhang", "id": "37086950750"}, {"name": "Xu Wang", "affiliation": "Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China", "firstName": "Xu", "lastName": "Wang", "id": "37601040400"}, {"name": "Hongyu Zhang", "affiliation": "The University of Newcastle, Australia", "firstName": "Hongyu", "lastName": "Zhang", "id": "37085471743"}, {"name": "Hailong Sun", "affiliation": "Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China", "firstName": "Hailong", "lastName": "Sun", "id": "37277693100"}, {"name": "Kaixuan Wang", "affiliation": "Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China", "firstName": "Kaixuan", "lastName": "Wang", "id": "37086947467"}, {"name": "Xudong Liu", "affiliation": "Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China", "firstName": "Xudong", "lastName": "Liu", "id": "37292955400"}], "abstract": "Exploiting machine learning techniques for analyzing programs has attracted much attention. One key problem is how to represent code fragments well for follow-up analysis. Traditional information retrieval based methods often treat programs as natural language texts, which could miss important semantic information of source code. Recently, state-of-the-art studies demonstrate that abstract syntax tree (AST) based neural models can better represent source code. However, the sizes of ASTs are usually large and the existing models are prone to the long-term dependency problem. In this paper, we propose a novel AST-based Neural Network (ASTNN) for source code representation. Unlike existing models that work on entire ASTs, ASTNN splits each large AST into a sequence of small statement trees, and encodes the statement trees to vectors by capturing the lexical and syntactical knowledge of statements. Based on the sequence of statement vectors, a bidirectional RNN model is used to leverage the naturalness of statements and finally produce the vector representation of a code fragment. We have applied our neural network based source code representation method to two common program comprehension tasks: source code classification and code clone detection. Experimental results on the two tasks indicate that our model is superior to state-of-the-art approaches.", "keywords": [{"type": "IEEE Keywords", "kwd": ["Syntactics", "Cloning", "Semantics", "Neural networks", "Task analysis", "Binary trees", "Natural languages"]}, {"type": "INSPEC: Controlled Indexing", "kwd": ["information retrieval", "learning (artificial intelligence)", "natural language processing", "program diagnostics", "recurrent neural nets", "text analysis", "tree data structures"]}, {"type": "INSPEC: Non-Controlled Indexing", "kwd": ["abstract syntax tree", "code fragment", "natural language texts", "ASTNN", "statement trees", "statement vectors", "bidirectional RNN model", "vector representation", "source code representation method", "source code classification", "code clone detection", "program analysis", "program comprehension tasks", "AST-based Neural Network", "neural source code representation", "information retrieval", "machine learning"]}, {"type": "Author Keywords ", "kwd": ["Abstract Syntax Tree, source code representation, neural network, code classification, code clone detection"]}], "publication": "2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)", "doi": "10.1109/ICSE.2019.00086", "ref": [{"order": "1", "text": "G. Frantzeskou, S. MacDonell, E. Stamatatos, S. Gritzalis, \"Exam-ining the significance of high-level programming features in source code author classification\", <em>Journal of Systems and Software</em>, vol. 81, no. 3, pp. 447-460, 2008.", "title": "Exam-ining the significance of high-level programming features in source code author classification", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec1", "text": " For example, programs are represented by token sequences or bag of tokens for code clone detection [3], [4], bug localization[11], and code authorship classification [1].", "part": "1"}, {"sec": "sec6a", "text": " Based on the statistical and machine learning methods, the n-gram model [1] and SVM [45] are used for classifying source code authorship and domains.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1016/j.jss.2007.03.004", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Exam-ining+the+significance+of+high-level+programming+features+in+source+code+author+classification&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref1"}, {"order": "2", "text": "L. Mou, G. Li, L. Zhang, T. Wang, Z. Jin, \"Convolutional neural networks over tree structures for programming language processing\", <em>AAAI</em>, vol. 2, no. 3, pp. 4, 2016.", "title": "Convolutional neural networks over tree structures for programming language processing", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec1", "text": " Even though code fragments have something in common with plain texts, they should not be simply dealt with text-based or token-based methods due to their richer and more explicit structural information [2], [18].", "part": "1"}, {"sec": "sec1", "text": "Recent work [2], [5], [6] provides the strong evidence that syntactic knowledge contributes more in modeling source code and can obtain better representation than traditional token-based methods.", "part": "1"}, {"sec": "sec1", "text": " These approaches combine Abstract Syntax Tree (AST)and Recursive Neural Network (RvNN)[5], Tree-based CNN [2] or Tree-LSTM [6] to capture both the lexical (i.e., the leaf nodes of ASTs such as identifiers)and syntactical (i.e., the non-leaf nodes of ASTs like the grammar construct WhileStatement) information.", "part": "1"}, {"sec": "sec1", "text": " As a result, traversing and encoding entire ASTs in a bottom-up way [5], [6] or using the sliding window technique [2] may lose long-term context information [19], [22]; Second, these approaches either transform ASTs to or directly view ASTs as full binary trees for simplification and efficiency, which destroys the original syntactic structure of source code and even make ASTs much deeper.", "part": "1"}, {"sec": "sec2b2", "text": "TBCNN performs convolution computation over tree structures for supervised learning such as source code classification [2].", "part": "1"}, {"sec": "sec3b2", "text": " However, generally batch processing on multiway ST-trees makes it difficult since the number of children nodes varies for the parent nodes in the same position of one batch [2], [6].", "part": "1"}, {"sec": "sec4", "text": "This task aims to classify code fragments by their functionalities, which is useful for program understanding and maintenance [2], [44], [45].", "part": "1"}, {"sec": "sec5a", "text": " [2]. 22https://sites.google.com/site/treebasedcnn/.", "part": "1"}, {"sec": "sec5c1", "text": " Apart from the state-of-the-art model TBCNN [2], we also take into account of traditional and other neural network based approaches including SVMs with statistical features, TextCNN [50], LSTM [51], LSCNN [52] and PDG-based Graph embedding approaches [25], [26] as follows:\n\n\n\u2022\nSVMs.", "part": "1"}, {"sec": "sec6a", "text": " TBCNN [2] uses custom convolutional neural network on ASTs to learn vector representations of code snippets.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Convolutional+neural+networks+over+tree+structures+for+programming+language+processing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref2"}, {"order": "3", "text": "T. Kamiya, S. Kusumoto, K. Inoue, \"CCFinder: a multilinguistic token-based code clone detection system for large scale source code\", <em>IEEE Transactions on Software Engineering</em>, vol. 28, no. 7, pp. 654-670, 2002.", "title": "CCFinder: a multilinguistic token-based code clone detection system for large scale source code", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec1", "text": " For example, programs are represented by token sequences or bag of tokens for code clone detection [3], [4], bug localization[11], and code authorship classification [1].", "part": "1"}, {"sec": "sec4", "text": "Detecting code clones is widely studied in software engineering research [3]\u2013[26], which is to detect whether two code fragments implement the same functionality.", "part": "1"}, {"sec": "sec6a", "text": " Programs are transformed to regularized token sequences for code clone detection [3].", "part": "1"}], "links": {"documentLink": "/document/1019480", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=1019480", "abstract": "A code clone is a code portion in source files that is identical or similar to another. Since code clones are believed to reduce the maintainability of software, several code clone detection techniques and tools have been proposed. This paper proposes a new clone detection technique, which consists of the transformation of input source text and a token-by-token comparison. For its implementation with several useful optimization techniques, we have developed a tool, named CCFinder (Code Clone Fin...", "pdfSize": "4706KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=CCFinder%3A+a+multilinguistic+token-based+code+clone+detection+system+for+large+scale+source+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref3"}, {"order": "4", "text": "H. Sajnani, V. Saini, J. Svajlenko, C. K. Roy, C. V. Lopes, \"SourcererCC: Scaling code clone detection to big-code\", <em>Software Engineering (ICSE) 2016 IEEE/ACM 38th International Conference</em>, pp. 1157-1168, 2016.", "title": "SourcererCC: Scaling code clone detection to big-code", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[4][6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec1", "text": " For example, programs are represented by token sequences or bag of tokens for code clone detection [3], [4], bug localization[11], and code authorship classification [1].", "part": "1"}, {"sec": "sec4", "text": "Detecting code clones is widely studied in software engineering research [3]\u2013[4][26], which is to detect whether two code fragments implement the same functionality.", "part": "1"}, {"sec": "sec6a", "text": " SourcererCC [4] has an improvement by exploiting token ordering along with an optimized inverted-index technique.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2884781.2884877", "abstract": "Despite a decade of active research, there has been a marked lack in clone detection techniques that scale to large repositories for detecting near-miss clones. In this paper, we present a token-based clone detector, SourcererCC, that can detect both exact and near-miss clones from large inter-project repositories using a standard workstation. It exploits an optimized inverted-index to quickly query the potential clones of a given code block. Filtering heuristics based on token ordering are used...", "pdfSize": "479KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=SourcererCC%3A+Scaling+code+clone+detection+to+big-code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref4"}, {"order": "5", "text": "M. White, M. Tufano, C. Vendome, D. Poshyvanyk, \"Deep learning code fragments for code clone detection\", <em>Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering</em>, pp. 87-98, 2016.", "title": "Deep learning code fragments for code clone detection", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[5][6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec1", "text": "Recent work [2], [5], [6] provides the strong evidence that syntactic knowledge contributes more in modeling source code and can obtain better representation than traditional token-based methods.", "part": "1"}, {"sec": "sec1", "text": " These approaches combine Abstract Syntax Tree (AST)and Recursive Neural Network (RvNN)[5], Tree-based CNN [2] or Tree-LSTM [6] to capture both the lexical (i.e., the leaf nodes of ASTs such as identifiers)and syntactical (i.e., the non-leaf nodes of ASTs like the grammar construct WhileStatement) information.", "part": "1"}, {"sec": "sec1", "text": " As a result, traversing and encoding entire ASTs in a bottom-up way [5], [6] or using the sliding window technique [2] may lose long-term context information [19], [22]; Second, these approaches either transform ASTs to or directly view ASTs as full binary trees for simplification and efficiency, which destroys the original syntactic structure of source code and even make ASTs much deeper.", "part": "1"}, {"sec": "sec2b1", "text": " Based on RvNN, a recursive autoencoder (RAE)is incorporated for automatically encoding ASTs to detect code clones [5], where ASTs are transformed to full binary trees due to the fixed-size inputs for simplification.", "part": "1"}, {"sec": "sec3a", "text": " If the size of selected granularity is too large (e.g., the full AST), similar to the related work [5], [6], we may also experience the gradient vanishing problem mentioned in Section II.", "part": "1"}, {"sec": "sec3b1", "text": " If we transform the ST-tree to one binary tree as described in [5], [6], for example, moving the node of readText to one child node or descendant of the FormalParameter node, the original semantics may be destroyed.", "part": "1"}, {"sec": "sec4", "text": "Detecting code clones is widely studied in software engineering research [3]\u2013[5][26], which is to detect whether two code fragments implement the same functionality.", "part": "1"}, {"sec": "sec5a", "text": " As benchmarks, the two datasets have been used by many researchers concerning on code similarity [48], [49] and clone detection [5], [6].", "part": "1"}, {"sec": "sec5c2", "text": " We compare our approach with existing state-of-the-art neural models for clone detection including RAE [5] and CDLH [6].", "part": "1"}, {"sec": "sec6a", "text": " [5] exploits a recursive auto-encoder over the ASTs with pre-trained token embeddings.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2970276.2970326", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Deep+learning+code+fragments+for+code+clone+detection&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref5"}, {"order": "6", "text": "H.-H. Wei, M. Li, \"Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code\", <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em>, pp. 3034-3040, 2017.", "title": "Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec1", "text": "Recent work [2], [5], [6] provides the strong evidence that syntactic knowledge contributes more in modeling source code and can obtain better representation than traditional token-based methods.", "part": "1"}, {"sec": "sec1", "text": " These approaches combine Abstract Syntax Tree (AST)and Recursive Neural Network (RvNN)[5], Tree-based CNN [2] or Tree-LSTM [6] to capture both the lexical (i.e., the leaf nodes of ASTs such as identifiers)and syntactical (i.e., the non-leaf nodes of ASTs like the grammar construct WhileStatement) information.", "part": "1"}, {"sec": "sec1", "text": " As a result, traversing and encoding entire ASTs in a bottom-up way [5], [6] or using the sliding window technique [2] may lose long-term context information [19], [22]; Second, these approaches either transform ASTs to or directly view ASTs as full binary trees for simplification and efficiency, which destroys the original syntactic structure of source code and even make ASTs much deeper.", "part": "1"}, {"sec": "sec2b3", "text": " CDLH [6] uses Tree-Lstm to learn representations of code fragments for clone detection where code fragments are parsed to ASTs.", "part": "1"}, {"sec": "sec2c", "text": " For example, CDLH [6] can only have the F1 value of 57% in one public benchmark for clone detection, and the studies in NLP [23], [41], [21] show that the tree size and depth do matter and have significant impact on the performance.", "part": "1"}, {"sec": "sec3a", "text": " If the size of selected granularity is too large (e.g., the full AST), similar to the related work [5], [6], we may also experience the gradient vanishing problem mentioned in Section II.", "part": "1"}, {"sec": "sec3b1", "text": " If we transform the ST-tree to one binary tree as described in [5], [6], for example, moving the node of readText to one child node or descendant of the FormalParameter node, the original semantics may be destroyed.", "part": "1"}, {"sec": "sec3b2", "text": " However, generally batch processing on multiway ST-trees makes it difficult since the number of children nodes varies for the parent nodes in the same position of one batch [2], [6].", "part": "1"}, {"sec": "sec4", "text": "Detecting code clones is widely studied in software engineering research [3]\u2013[6][26], which is to detect whether two code fragments implement the same functionality.", "part": "1"}, {"sec": "sec5a", "text": " As benchmarks, the two datasets have been used by many researchers concerning on code similarity [48], [49] and clone detection [5], [6].", "part": "1"}, {"sec": "sec5c2", "text": "As Table I shows, similar to the previous work [6], we choose 500 programs from each of the first 15 programming problems in OJ, namely OJClone.", "part": "1"}, {"sec": "sec5c2", "text": " We compare our approach with existing state-of-the-art neural models for clone detection including RAE [5] and CDLH [6].", "part": "1"}, {"sec": "sec5d", "text": " In Table III, as mentioned before, we cite the results of CDLH from [6].", "part": "1"}, {"sec": "sec5d", "text": " The BCB-ALL is a weighted sum result according to the percentage of various clone types [6].", "part": "1"}, {"sec": "sec6a", "text": " CDLH [6] incorporates Tree-LSTM to represent the functionality semantics of code fragments.", "part": "1"}, {"sec": "sec7", "text": " This leads to the uncertainty about whether they are true clone pairs, although similar practice has been done by previous work [6].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.24963/ijcai.2017/423", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Supervised+deep+features+for+software+functional+clone+detection+by+exploiting+lexical+and+syntactical+information+in+source+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref6"}, {"order": "7", "text": "M. Dambros, M. Lanza, R. Robbes, \"Evaluating defect prediction approaches: a benchmark and an extensive comparison\", <em>Empirical Software Engineering</em>, vol. 17, no. 4-5, pp. 531-577, 2012.", "title": "Evaluating defect prediction approaches: a benchmark and an extensive comparison", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/s10664-011-9173-9", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Evaluating+defect+prediction+approaches%3A+a+benchmark+and+an+extensive+comparison&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref7"}, {"order": "8", "text": "C. Tantithamthavorn, S. McIntosh, A. E. Hassan, K. Matsumoto, \"An empirical comparison of model validation techniques for defect prediction models\", <em>IEEE Transactions on Software Engineering</em>, vol. 43, no. 1, pp. 1-18, 2017.", "title": "An empirical comparison of model validation techniques for defect prediction models", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}], "links": {"documentLink": "/document/7497471", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=7497471", "abstract": "Defect prediction models help software quality assurance teams to allocate their limited resources to the most defect-prone modules. Model validation techniques, such as $k$ -fold cross-validation, use historical data to estimate how well a model will perform in the future. However, little is known about how accurate the estimates of model validation techniques tend to be. In this paper, we investigate the bias and variance of model validation techniques in the domain of defect prediction. Analy...", "pdfSize": "2074KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=An+empirical+comparison+of+model+validation+techniques+for+defect+prediction+models&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref8"}, {"order": "9", "text": "S. Haiduc, J. Aponte, A. Marcus, \"Supporting program comprehension with source code summarization\", <em>Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering-Volume 2</em>, pp. 223-226, 2010.", "title": "Supporting program comprehension with source code summarization", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/1810295.1810335", "abstract": "One of the main challenges faced by today&#39;s developers is keeping up with the staggering amount of source code that needs to be read and understood. In order to help developers with this problem and reduce the costs associated with it, one solution is to use simple textual descriptions of source code entities that developers can grasp easily, while capturing the code semantics precisely. We propose an approach to automatically determine such descriptions, based on automated text summarization te...", "pdfSize": "166KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Supporting+program+comprehension+with+source+code+summarization&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref9"}, {"order": "10", "text": "S. Jiang, A. Armaly, C. McMillan, \"Automatically generating commit messages from diffs using neural machine translation\", <em>Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering</em>, pp. 135-146, 2017.", "title": "Automatically generating commit messages from diffs using neural machine translation", "context": [{"sec": "sec1", "text": "Many software engineering methods, such as source code classification [1], [2], code clone detection [3]\u2013[6], defect prediction [7], [8] and code summarization [9], [10] have been proposed to improve software development and maintenance.", "part": "1"}, {"sec": "sec6b", "text": " The neural machine translation is used to automatically generate commit messages [10].", "part": "1"}], "links": {"documentLink": "/document/8115626", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=8115626", "abstract": "Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, human...", "pdfSize": "732KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Automatically+generating+commit+messages+from+diffs+using+neural+machine+translation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref10"}, {"order": "11", "text": "J. Zhou, H. Zhang, D. Lo, \"Where should the bugs be fixed? more accurate information retrieval-based bug localization based on bug reports\", <em>2012 34th International Conference on Software Engineering (ICSE)</em>, pp. 14-24, June 2012.", "title": "Where should the bugs be fixed? more accurate information retrieval-based bug localization based on bug reports", "context": [{"sec": "sec1", "text": " For example, programs are represented by token sequences or bag of tokens for code clone detection [3], [4], bug localization[11], and code authorship classification [1].", "part": "1"}], "links": {"documentLink": "/document/6227210", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6227210", "abstract": "For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all file...", "pdfSize": "343KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Where+should+the+bugs+be+fixed%3F+more+accurate+information+retrieval-based+bug+localization+based+on+bug+reports&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref11"}, {"order": "12", "text": "S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, R. Harshman, \"Indexing by latent semantic analysis\", <em>Journal of the American society for information science</em>, vol. 41, no. 6, pp. 391, 1990.", "title": "Indexing by latent semantic analysis", "context": [{"sec": "sec1", "text": " In addition, a number of researchers use Latent Semantic Indexing (LSI)[12] and Latent Dirichlet Allocation (LDA)[13] to analyze source code [14]\u2013[16].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Indexing+by+latent+semantic+analysis&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref12"}, {"order": "13", "text": "D. M. Blei, A. Y. Ng, M. I. Jordan, \"Latent dirichlet allocation\", <em>Journal of machine Learning research</em>, vol. 3, no. Jan, pp. 993-1022, 2003.", "title": "Latent dirichlet allocation", "context": [{"sec": "sec1", "text": " In addition, a number of researchers use Latent Semantic Indexing (LSI)[12] and Latent Dirichlet Allocation (LDA)[13] to analyze source code [14]\u2013[16].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Latent+dirichlet+allocation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref13"}, {"order": "14", "text": "R. Tairas, J. Gray, \"An information retrieval process to aid in the analysis of code clones\", <em>Empirical Software Engineering</em>, vol. 14, no. 1, pp. 33-56, 2009.", "title": "An information retrieval process to aid in the analysis of code clones", "context": [{"sec": "sec1", "text": " In addition, a number of researchers use Latent Semantic Indexing (LSI)[12] and Latent Dirichlet Allocation (LDA)[13] to analyze source code [14]\u2013[16].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/s10664-008-9089-1", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=An+information+retrieval+process+to+aid+in+the+analysis+of+code+clones&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref14"}, {"order": "15", "text": "Y. Liu, D. Poshyvanyk, R. Ferenc, T. Gyim\u00f3thy, N. Chrisochoides, \"Modeling class cohesion as mixtures of latent topics\", <em>Software Maintenance 2009. ICSM 2009. IEEE International Conference</em>, pp. 233-242, 2009.", "title": "Modeling class cohesion as mixtures of latent topics", "context": [{"sec": "sec1", "text": " In addition, a number of researchers use Latent Semantic Indexing (LSI)[12] and Latent Dirichlet Allocation (LDA)[13] to analyze source code [14]\u2013[15][16].", "part": "1"}, {"sec": "sec6a", "text": " Maletic et al. [56] adopts LSI to identify semantic similarities of code fragments, and the cohesion of classes in software is evaluated by LDA [15].", "part": "1"}], "links": {"documentLink": "/document/5306318", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=5306318", "abstract": "The paper proposes a new measure for the cohesion of classes in object-oriented software systems. It is based on the analysis of latent topics embedded in comments and identifiers in source code. The measure, named as maximal weighted entropy, utilizes the latent Dirichlet allocation technique and information entropy measures to quantitatively evaluate the cohesion of classes in software. This paper presents the principles and the technology that stand behind the proposed measure. Two case studi...", "pdfSize": "420KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Modeling+class+cohesion+as+mixtures+of+latent+topics&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref15"}, {"order": "16", "text": "A. De Lucia, M. Di Penta, R. Oliveto, A. Panichella, S. Panichella, \"Using IR methods for labeling source code artifacts: Is it worthwhile?\", <em>Program Comprehension (ICPC) 2012 IEEE 20th International Conference</em>, pp. 193-202, 2012.", "title": "Using IR methods for labeling source code artifacts: Is it worthwhile?", "context": [{"sec": "sec1", "text": " In addition, a number of researchers use Latent Semantic Indexing (LSI)[12] and Latent Dirichlet Allocation (LDA)[13] to analyze source code [14]\u2013[16].", "part": "1"}], "links": {"documentLink": "/document/6240488", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6240488", "abstract": "Information Retrieval (IR) techniques have been used for various software engineering tasks, including the labeling of software artifacts by extracting \u201ckeywords\u201d from them. Such techniques include Vector Space Models, Latent Semantic Indexing, Latent Dirichlet Allocation, as well as customized heuristics extracting words from specific source code elements. This paper investigates how source code artifact labeling performed by IR techniques would overlap (and differ) from labeling performed by h...", "pdfSize": "595KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Using+IR+methods+for+labeling+source+code+artifacts%3A+Is+it+worthwhile%3F&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref16"}, {"order": "17", "text": "A. Panichella, B. Dit, R. Oliveto, M. Di Penta, D. Poshynanyk, A. De Lucia, \"How to effectively use topic models for software engineering tasks? an approach based on genetic algorithms\", <em>Software Engineering (ICSE) 2013 35th International Conference</em>, pp. 522-531, 2013.", "title": "How to effectively use topic models for software engineering tasks? an approach based on genetic algorithms", "context": [{"sec": "sec1", "text": " However, according to [17], the common problem of these approaches is that they assume the underlying corpus (i.e., the source code)is composed of natural language texts.", "part": "1"}, {"sec": "sec2a", "text": " Due to the limitation of token-based approaches [17], these methods can catch little syntactical information of source code.", "part": "1"}], "links": {"documentLink": "/document/6606598", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6606598", "abstract": "Information Retrieval (IR) methods, and in particular topic models, have recently been used to support essential software engineering (SE) tasks, by enabling software textual retrieval and analysis. In all these approaches, topic models have been used on software artifacts in a similar manner as they were used on natural language documents (e.g., using the same settings and parameters) because the underlying assumption was that source code and natural language documents are similar. However, app...", "pdfSize": "392KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=How+to+effectively+use+topic+models+for+software+engineering+tasks%3F+an+approach+based+on+genetic+algorithms&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref17"}, {"order": "18", "text": "J. F. Pane, B. A. Myers et al., \"Studying the language and structure in non-programmers' solutions to programming problems\", <em>International Journal of Human-Computer Studies</em>, vol. 54, no. 2, pp. 237-264, 2001.", "title": "Studying the language and structure in non-programmers' solutions to programming problems", "context": [{"sec": "sec1", "text": " Even though code fragments have something in common with plain texts, they should not be simply dealt with text-based or token-based methods due to their richer and more explicit structural information [2], [18].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1006/ijhc.2000.0410", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Studying+the+language+and+structure+in+non-programmers%27+solutions+to+programming+problems&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref18"}, {"order": "19", "text": "Y. Bengio, P. Simard, P. Frasconi, \"Learning long-term dependencies with gradient descent is difficult\", <em>IEEE transactions on neural networks</em>, vol. 5, no. 2, pp. 157-166, 1994.", "title": "Learning long-term dependencies with gradient descent is difficult", "context": [{"sec": "sec1", "text": " First, similar to long texts in NLP, these tree-based neural models are also vulnerable to the gradient vanishing problem that the gradient becomes vanishingly small during training, especially when the tree is very large and deep [19]\u2013[21].", "part": "1"}, {"sec": "sec1", "text": " As a result, traversing and encoding entire ASTs in a bottom-up way [5], [6] or using the sliding window technique [2] may lose long-term context information [19], [22]; Second, these approaches either transform ASTs to or directly view ASTs as full binary trees for simplification and efficiency, which destroys the original syntactic structure of source code and even make ASTs much deeper.", "part": "1"}, {"sec": "sec2c", "text": " Thus the bottom-up computations from the leaf nodes to the root nodes may experience the gradient vanishing problem and are difficult to capture long-range dependencies [19], [22], which will miss some of the semantics carried by distant nodes from the root nodes such as identifiers in the leaf nodes.", "part": "1"}], "links": {"documentLink": "/document/279181", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=279181", "abstract": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These res...", "pdfSize": "1180KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Learning+long-term+dependencies+with+gradient+descent+is+difficult&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref19"}, {"order": "20", "text": "S. Hochreiter, \"The vanishing gradient problem during learning recurrent neural nets and problem solutions\", <em>Int. J. Uncertain Fuzziness Knowl.-Based Syst.</em>, vol. 6, no. 2, pp. 107-116, Apr. 1998.", "title": "The vanishing gradient problem during learning recurrent neural nets and problem solutions", "context": [{"sec": "sec1", "text": " First, similar to long texts in NLP, these tree-based neural models are also vulnerable to the gradient vanishing problem that the gradient becomes vanishingly small during training, especially when the tree is very large and deep [19]\u2013[20][21].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1142/S0218488598000094", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=The+vanishing+gradient+problem+during+learning+recurrent+neural+nets+and+problem+solutions&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref20"}, {"order": "21", "text": "P. Le, W. H. Zuidema, \"Quantifying the vanishing gradient and long distance dependency problem in recursive neural networks and recursive LSTMs\", <em>Proceedings of the 1st Workshop on Representation Learning for NLP</em>, 2016.", "title": "Quantifying the vanishing gradient and long distance dependency problem in recursive neural networks and recursive LSTMs", "context": [{"sec": "sec1", "text": " First, similar to long texts in NLP, these tree-based neural models are also vulnerable to the gradient vanishing problem that the gradient becomes vanishingly small during training, especially when the tree is very large and deep [19]\u2013[21].", "part": "1"}, {"sec": "sec2c", "text": " For example, CDLH [6] can only have the F1 value of 57% in one public benchmark for clone detection, and the studies in NLP [23], [41], [21] show that the tree size and depth do matter and have significant impact on the performance.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.18653/v1/W16-1610", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Quantifying+the+vanishing+gradient+and+long+distance+dependency+problem+in+recursive+neural+networks+and+recursive+LSTMs&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref21"}, {"order": "22", "text": "S.-Y. Cho, Z. Chi, W.-C. Siu, A. C. Tsoi, \"An improved algorithm for learning long-term dependency problems in adaptive processing of data structures\", <em>IEEE Transactions on Neural Networks</em>, vol. 14, no. 4, pp. 781-793, 2003.", "title": "An improved algorithm for learning long-term dependency problems in adaptive processing of data structures", "context": [{"sec": "sec1", "text": " As a result, traversing and encoding entire ASTs in a bottom-up way [5], [6] or using the sliding window technique [2] may lose long-term context information [19], [22]; Second, these approaches either transform ASTs to or directly view ASTs as full binary trees for simplification and efficiency, which destroys the original syntactic structure of source code and even make ASTs much deeper.", "part": "1"}, {"sec": "sec2c", "text": " Thus the bottom-up computations from the leaf nodes to the root nodes may experience the gradient vanishing problem and are difficult to capture long-range dependencies [19], [22], which will miss some of the semantics carried by distant nodes from the root nodes such as identifiers in the leaf nodes.", "part": "1"}], "links": {"documentLink": "/document/1215396", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=1215396", "abstract": "Many researchers have explored the use of neural-network representations for the adaptive processing of data structures. One of the most popular learning formulations of data structure processing is backpropagation through structure (BPTS). The BPTS algorithm has been successful applied to a number of learning tasks that involve structural patterns such as logo and natural scene classification. The main limitations of the BPTS algorithm are attributed to slow convergence speed and the long-term ...", "pdfSize": "1001KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=An+improved+algorithm+for+learning+long-term+dependency+problems+in+adaptive+processing+of+data+structures&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref22"}, {"order": "23", "text": "X. Zhu, P. Sobhani, H. Guo, \"Long short-term memory over recursive structures\", <em>Proceedings of the 32Nd International Conference on International Conference on Machine Learning</em>, vol. 37, pp. 1604-1612, 2015.", "title": "Long short-term memory over recursive structures", "context": [{"sec": "sec1", "text": " The transformed and deeper ASTs further weaken the capability of neural models to capture more real and complex semantics [23].", "part": "1"}, {"sec": "sec2c", "text": " First, during gradient-based training of tree topologies, the gradients are calculated via backpropagation over structures [41], [23].", "part": "1"}, {"sec": "sec2c", "text": " For example, CDLH [6] can only have the F1 value of 57% in one public benchmark for clone detection, and the studies in NLP [23], [41], [21] show that the tree size and depth do matter and have significant impact on the performance.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Long+short-term+memory+over+recursive+structures&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref23"}, {"order": "24", "text": "M. Ou, P. Cui, J. Pei, Z. Zhang, W. Zhu, \"Asymmetric transitivity preserving graph embedding\", <em>Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, pp. 1105-1114, 2016.", "title": "Asymmetric transitivity preserving graph embedding", "context": [{"sec": "sec1", "text": "In order to overcome the limitations of the above AST-based neural networks, one solution is to introduce explicit (long-term)control flow and data dependencies graphs and employ a Graph Embedding technique [24] to represent source code.", "part": "1"}, {"sec": "sec5c1", "text": " Most recently some studies [25], [26] construct program graphs by considering control flow and data flow dependencies, and adopt graph embedding techniques such as HOPE [24] and Gated Graph Neural Network (GGNN) [53] for code representation.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2939672.2939751", "abstract": "Graph embedding algorithms embed a graph into a vector space where the structure and the inherent properties of the graph are preserved. The existing graph embedding methods cannot preserve the asymmetric transitivity well, which is a critical property of directed graphs. Asymmetric transitivity depicts the correlation among directed edges, that is, if there is a directed path from u to v, then there is likely a directed edge from u to v. Asymmetric transitivity can help in capturing structures ...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Asymmetric+transitivity+preserving+graph+embedding&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref24"}, {"order": "25", "text": "M. Allamanis, M. Brockschmidt, M. Khademi, \"Learning to represent programs with graphs\", <em>International Conference on Learning Representations</em>, 2018,  [online]  Available: https://openreview.net/forum?id=BJOFETxR-.", "title": "Learning to represent programs with graphs", "context": [{"sec": "sec1", "text": " For instance, one recent study considers the long-range dependencies induced by the same variable or function in distant locations [25].", "part": "1"}, {"sec": "sec5c1", "text": " Apart from the state-of-the-art model TBCNN [2], we also take into account of traditional and other neural network based approaches including SVMs with statistical features, TextCNN [50], LSTM [51], LSCNN [52] and PDG-based Graph embedding approaches [25], [26] as follows:\n\n\n\u2022\nSVMs.", "part": "1"}, {"sec": "sec5c1", "text": " Most recently some studies [25], [26] construct program graphs by considering control flow and data flow dependencies, and adopt graph embedding techniques such as HOPE [24] and Gated Graph Neural Network (GGNN) [53] for code representation.", "part": "1"}, {"sec": "sec5c1", "text": " Based on the PDGs, we represents nodes of PDGs by the numerical ID of statements in HOPE [26], and average the embeddings of all tokens in each PDG node as its initial embedding [25] in GGNN66https://github.com/Microsoft/gated-graph-neural-network-samples.", "part": "1"}, {"sec": "sec5c1", "text": " Most recently some studies [25], [26] construct program graphs by considering control flow and data flow dependencies, and adopt graph embedding techniques such as HOPE [24] and Gated Graph Neural Network (GGNN) [53] for code representation.", "part": "1"}, {"sec": "sec5c1", "text": " Based on the PDGs, we represents nodes of PDGs by the numerical ID of statements in HOPE [26], and average the embeddings of all tokens in each PDG node as its initial embedding [25] in GGNN66https://github.com/Microsoft/gated-graph-neural-network-samples.", "part": "1"}, {"sec": "sec6a", "text": " [25] performs Gated Graph Neural Networks on program graphs which track the dependencies of the same variables and functions to predict variable names and detect variable misuses.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Learning+to+represent+programs+with+graphs&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref25"}, {"order": "26", "text": "G. B. M. D. P. M. W. Michele Tufano, Cody Watson, D. Poshyvanyk, \"Deep learning similarities from different representations of source code\", <em>15th International Conference on Mining Software Repositories</em>, 2018.", "title": "Deep learning similarities from different representations of source code", "context": [{"sec": "sec1", "text": " Another study directly constructs control flow graphs (CFGs)of code fragments [26].", "part": "1"}, {"sec": "sec4", "text": "Detecting code clones is widely studied in software engineering research [3]\u2013[26], which is to detect whether two code fragments implement the same functionality.", "part": "1"}, {"sec": "sec5c1", "text": " Apart from the state-of-the-art model TBCNN [2], we also take into account of traditional and other neural network based approaches including SVMs with statistical features, TextCNN [50], LSTM [51], LSCNN [52] and PDG-based Graph embedding approaches [25], [26] as follows:\n\n\n\u2022\nSVMs.", "part": "1"}, {"sec": "sec5c1", "text": " Most recently some studies [25], [26] construct program graphs by considering control flow and data flow dependencies, and adopt graph embedding techniques such as HOPE [24] and Gated Graph Neural Network (GGNN) [53] for code representation.", "part": "1"}, {"sec": "sec5c1", "text": " Based on the PDGs, we represents nodes of PDGs by the numerical ID of statements in HOPE [26], and average the embeddings of all tokens in each PDG node as its initial embedding [25] in GGNN66https://github.com/Microsoft/gated-graph-neural-network-samples.", "part": "1"}, {"sec": "sec5c1", "text": " Most recently some studies [25], [26] construct program graphs by considering control flow and data flow dependencies, and adopt graph embedding techniques such as HOPE [24] and Gated Graph Neural Network (GGNN) [53] for code representation.", "part": "1"}, {"sec": "sec5c1", "text": " Based on the PDGs, we represents nodes of PDGs by the numerical ID of statements in HOPE [26], and average the embeddings of all tokens in each PDG node as its initial embedding [25] in GGNN66https://github.com/Microsoft/gated-graph-neural-network-samples.", "part": "1"}, {"sec": "sec5d", "text": " In particular, PDG with HOPE gets an accuracy of only 4.2%, because the nodes of PDGs are represented by their numerical ID which miss lexical knowledge and only focuses on the explicit dependency information in a high abstraction level [26].", "part": "1"}, {"sec": "sec6a", "text": " Multiple different code representations such as identifiers, CFGs and bytecodes can also be integrated by the ensemble learning technique [26].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/3196398.3196431", "abstract": "Assessing the similarity between code components plays a pivotal role in a number of Software Engineering (SE) tasks, such as clone detection, impact analysis, refactoring, etc. Code similarity is generally measured by relying on manually defined or hand-crafted features, e.g., by analyzing the overlap among identifiers or comparing the Abstract Syntax Trees of two code components. These features represent a best guess at what SE researchers can utilize to exploit and reliably assess code simila...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Deep+learning+similarities+from+different+representations+of+source+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref26"}, {"order": "27", "text": "J. Ferrante, K. J. Ottenstein, J. D. Warren, \"The program dependence graph and its use in optimization\", <em>ACM Trans. Program. Lang. Syst.</em>, vol. 9, no. 3, pp. 319-349, Jul. 1987.", "title": "The program dependence graph and its use in optimization", "context": [{"sec": "sec1", "text": " However, as depicted in the above work, precise and inter-procedural program dependency graphs (PDGs)(i.e. control flow and data flow dependencies)[27] usually rely on compiled intermediate representations or bytecodes [28], [29], and are not applicable to uncompilable and incomplete code fragments.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/3-540-12925-1_33", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=The+program+dependence+graph+and+its+use+in+optimization&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref27"}, {"order": "28", "text": "E. M. Myers, \"A precise inter-procedural data flow algorithm\", <em>Proceedings of the 8th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</em>, pp. 219-230, 1981.", "title": "A precise inter-procedural data flow algorithm", "context": [{"sec": "sec1", "text": " However, as depicted in the above work, precise and inter-procedural program dependency graphs (PDGs)(i.e. control flow and data flow dependencies)[27] usually rely on compiled intermediate representations or bytecodes [28], [29], and are not applicable to uncompilable and incomplete code fragments.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/567532.567556", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+precise+inter-procedural+data+flow+algorithm&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref28"}, {"order": "29", "text": "\"Llvms analysis and transform passes\",  [online]  Available: https://llvm.org/docs/Passes.html.", "title": "Llvms analysis and transform passes", "context": [{"sec": "sec1", "text": " However, as depicted in the above work, precise and inter-procedural program dependency graphs (PDGs)(i.e. control flow and data flow dependencies)[27] usually rely on compiled intermediate representations or bytecodes [28], [29], and are not applicable to uncompilable and incomplete code fragments.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Llvms+analysis+and+transform+passes&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref29"}, {"order": "30", "text": "J. Gosling, B. Joy, G. L. Steele, G. Bracha, A. Buckley, The Java Language Specification Java SE 8 Edition, Addison-Wesley Professional, 2014.", "title": "The Java Language Specification, Java SE 8 Edition", "context": [{"sec": "sec1", "text": " Here statements refer to the Statement AST nodes defined in program language specification [30].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=The+Java+Language+Specification%2C+Java+SE+8+Edition&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref30"}, {"order": "31", "text": "T. Mikolov, M. Karafi\u00e1t, L. Burget, J. \u010cernock\u00fd, S. Khudanpur, \"Recurrent neural network based language model\", <em>Eleventh Annual Conference of the International Speech Communication Association</em>, 2010.", "title": "Recurrent neural network based language model", "context": [{"sec": "sec1", "text": " We use Recurrent Neural Network (RNN)[31] to encode statements and the sequential dependency between the statements into a vector.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Recurrent+neural+network+based+language+model&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref31"}, {"order": "32", "text": "A. Hindle, E. T. Barr, Z. Su, M. Gabel, P. Devanbu, \"On the naturalness of software\", <em>Software Engineering (ICSE) 2012 34th International Conference</em>, pp. 837-847, 2012.", "title": "On the naturalness of software", "context": [{"sec": "sec1", "text": " Such a vector captures the naturalness of source code [32], [33] and can serve as a neural source code representation.", "part": "1"}], "links": {"documentLink": "/document/6227135", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6227135", "abstract": "Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal s...", "pdfSize": "383KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+naturalness+of+software&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref32"}, {"order": "33", "text": "B. Ray, V. Hellendoorn, S. Godhane, Z. Tu, A. Bacchelli, P. Devanbu, \"On the \u201cnaturalness\u201d of buggy code\", <em>Proceedings of the 38th International Conference on Software Engineering</em>, pp. 428-439, 2016.", "title": "On the \u201cnaturalness\u201d of buggy code", "context": [{"sec": "sec1", "text": " Such a vector captures the naturalness of source code [32], [33] and can serve as a neural source code representation.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2884781.2884848", "abstract": "Real software, the kind working programmers produce by the kLOC to solve real-world problems, tends to be \u201cnatural\u201d, like speech or natural language; it tends to be highly repetitive and predictable. Researchers have captured this naturalness of software through statistical models and used them to good effect in suggestion engines, porting tools, coding standards checkers, and idiom miners. This suggests that code that appears improbable, or surprising, to a good statistical language model is \u201cu...", "pdfSize": "629KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+%E2%80%9Cnaturalness%E2%80%9D+of+buggy+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref33"}, {"order": "34", "text": "D. Bahdanau, K. Cho, Y. Bengio, Neural machine translation by jointly learning to align and translate, 2014.", "title": "Neural machine translation by jointly learning to align and translate", "context": [{"sec": "sec1", "text": " Third, based on the sequence of statement vectors, we use bidirectional Gated Recurrent Unit (GRU)[34], [35], one type of recurrent neural network, to leverage the sequential naturalness of statements and finally obtain the vector representation of an entire code fragment.", "part": "1"}, {"sec": "sec3c", "text": "Based on the sequences of ST-tree vectors, we exploit GRU [34] to track the naturalness of statements.", "part": "1"}, {"sec": "sec3c", "text": "In order to further enhance the capability of the recurrent layer for capturing the dependency information, we adopt a bidirectional GRU [34], where the hidden states of both directions are concatenated to form the new states as follows:.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Neural+machine+translation+by+jointly+learning+to+align+and+translate&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref34"}, {"order": "35", "text": "D. Tang, B. Qin, T. Liu, \"Document modeling with gated recurrent neural network for sentiment classification\", <em>Proceedings of the 2015 conference on empirical methods in natural language processing</em>, pp. 1422-1432, 2015.", "title": "Document modeling with gated recurrent neural network for sentiment classification", "context": [{"sec": "sec1", "text": " Third, based on the sequence of statement vectors, we use bidirectional Gated Recurrent Unit (GRU)[34], [35], one type of recurrent neural network, to leverage the sequential naturalness of statements and finally obtain the vector representation of an entire code fragment.", "part": "1"}, {"sec": "sec3", "text": " We then use Bidirectional Gated Recurrent Unit [35] (Bi-GRU), to model the naturalness of the statements.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.18653/v1/D15-1167", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Document+modeling+with+gated+recurrent+neural+network+for+sentiment+classification&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref35"}, {"order": "36", "text": "I. D. Baxter, A. Yahin, L. Moura, M. Sant'Anna, L. Bier, \"Clone detection using abstract syntax trees\", <em>Software Maintenance 1998. Proceedings. International Conference</em>, pp. 368-377, 1998.", "title": "Clone detection using abstract syntax trees", "context": [{"sec": "sec2a", "text": "Abstract Syntax Tree (AST) is a kind of tree aimed at representing the abstract syntactic structure of the source code [36].", "part": "1"}], "links": {"documentLink": "/document/738528", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=738528", "abstract": "Existing research suggests that a considerable fraction (5-10%) of the source code of large scale computer programs is duplicate code (&#34;clones&#34;). Detection and removal of such clones promises decreased software maintenance costs of possibly the same magnitude. Previous work was limited to detection of either near misses differing only in single lexems, or near misses only between complete functions. The paper presents simple and practical methods for detecting exact and near miss clones over arb...", "pdfSize": "75KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Clone+detection+using+abstract+syntax+trees&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref36"}, {"order": "37", "text": "S. Paul, A. Prakash, \"A framework for source code search using program patterns\", <em>IEEE Transactions on Software Engineering</em>, vol. 20, no. 6, pp. 463-475, 1994.", "title": "A framework for source code search using program patterns", "context": [{"sec": "sec2a", "text": "Some studies directly use ASTs in token-based methods for source code search [37], program repair [38] and source code differencing [39].", "part": "1"}], "links": {"documentLink": "/document/295894", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=295894", "abstract": "For maintainers involved in understanding and reengineering large software, locating source code fragments that match certain patterns is a critical task. Existing solutions to the problem are few, and they either involve manual, painstaking scans of the source code using tools based on regular expressions, or the use of large, integrated software engineering environments that include simple pattern-based query processors in their toolkits. We present a framework in which pattern languages are u...", "pdfSize": "1097KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+framework+for+source+code+search+using+program+patterns&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref37"}, {"order": "38", "text": "W. Weimer, T. Nguyen, C. Le Goues, S. Forrest, \"Automatically finding patches using genetic programming\", <em>Proceedings of the 31 st International Conference on Software Engineering</em>, pp. 364-374, 2009.", "title": "Automatically finding patches using genetic programming", "context": [{"sec": "sec2a", "text": "Some studies directly use ASTs in token-based methods for source code search [37], program repair [38] and source code differencing [39].", "part": "1"}], "links": {"documentLink": "/document/5070536", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=5070536", "abstract": "Automatic program repair has been a longstanding goal in software engineering, yet debugging remains a largely manual process. We introduce a fully automated method for locating and repairing bugs in software. The approach works on off-the-shelf legacy applications and does not require formal specifications, program annotations or special coding practices. Once a program fault is discovered, an extended form of genetic programming is used to evolve program variants until one is found that both r...", "pdfSize": "264KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Automatically+finding+patches+using+genetic+programming&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref38"}, {"order": "39", "text": "J.-R. Falleri, F. Morandat, X. Blanc, M. Martinez, M. Monperrus, \"Fine-grained and accurate source code differencing\", <em>Proceedings of the 29th ACM/IEEE international conference on Automated software engineering</em>, pp. 313-324, 2014.", "title": "Fine-grained and accurate source code differencing", "context": [{"sec": "sec2a", "text": "Some studies directly use ASTs in token-based methods for source code search [37], program repair [38] and source code differencing [39].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2642937.2642982", "abstract": "At the heart of software evolution is a sequence of edit actions, called an edit script, made to a source code file. Since software systems are stored version by version, the edit script has to be computed from these versions, which is known as a complex task. Existing approaches usually compute edit scripts at the text granularity with only add line and delete line actions. However, inferring syntactic changes from such an edit script is hard. Since moving code is a frequent action performed wh...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Fine-grained+and+accurate+source+code+differencing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref39"}, {"order": "40", "text": "R. Socher, C. C. Lin, C. Manning, A. Y. Ng, \"Parsing natural scenes and natural language with recursive neural networks\", <em>Proceedings of the 28th international conference on machine learning (ICML-11)</em>, pp. 129-136, 2011.", "title": "Parsing natural scenes and natural language with recursive neural networks", "context": [{"sec": "sec2b1", "text": "RvNN was first proposed for the recursive structure in natural language and image parsing [40].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Parsing+natural+scenes+and+natural+language+with+recursive+neural+networks&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref40"}, {"order": "41", "text": "K. S. Tai, R. Socher, C. D. Manning, \"Improved semantic representations from tree-structured long short-term memory networks\", <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, vol. 1, pp. 1556-1566, 2015.", "title": "Improved semantic representations from tree-structured long short-term memory networks", "context": [{"sec": "sec2b3", "text": " Different from standard LSTM, Child-Sum Tree-LSTM [41] recursively combines current input with its children states for state updating across the tree structure.", "part": "1"}, {"sec": "sec2c", "text": " First, during gradient-based training of tree topologies, the gradients are calculated via backpropagation over structures [41], [23].", "part": "1"}, {"sec": "sec2c", "text": " For example, CDLH [6] can only have the F1 value of 57% in one public benchmark for clone detection, and the studies in NLP [23], [41], [21] show that the tree size and depth do matter and have significant impact on the performance.", "part": "1"}, {"sec": "sec4", "text": " Suppose there are code fragment vectors \\$r_{1}\\$ and \\$r_{2}\\$, and their distance is measured by \\$r=\\vert r_{1}-r_{2}\\vert\\$ for semantic relatedness [41].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.3115/v1/P15-1150", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Improved+semantic+representations+from+tree-structured+long+short-term+memory+networks&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref41"}, {"order": "42", "text": "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, J. Dean, \"Distributed representations of words and phrases and their compositionality\", <em>Advances in neural information processing systems</em>, pp. 3111-3119, 2013.", "title": "Distributed representations of words and phrases and their compositionality", "context": [{"sec": "sec3b1", "text": " The word2vec [42] is used to learn unsupervised vectors of the symbols, and the trained embeddings of symbols are served as initial parameters in the statement encoder.", "part": "1"}, {"sec": "sec5b", "text": " For both tasks, we trained embeddings of symbols using word2vec [42] with Skip-gram algorithm and set the embedding size to be 128.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Distributed+representations+of+words+and+phrases+and+their+compositionality&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref42"}, {"order": "43", "text": "X. Gu, H. Zhang, D. Zhang, S. Kim, \"Deep API learning\", <em>Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</em>, pp. 631-642, 2016.", "title": "Deep API learning", "context": [{"sec": "sec3c", "text": " Considering the importance of different statements are intuitively not equal, for example, API calls in the MethodInvocation statements may contain more functional information [43], thus we use max pooling for capturing the most important semantics by default.", "part": "1"}, {"sec": "sec6b", "text": " DeepAPI [43] uses a sequence-to-sequence neural network to learn representations of natural language queries and predict relevant API sequences.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2950290.2950334", "abstract": "Developers often wonder how to implement a certain functionality (e.g., how to parse XML files) using APIs. Obtaining an API usage sequence based on an API-related natural language query is very helpful in this regard. Given a query, existing approaches utilize information retrieval models to search for matching API sequences. These approaches treat queries and APIs as bags-of-words and lack a deep understanding of the semantics of the query. We propose DeepAPI, a deep learning based approach to...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Deep+API+learning&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref43"}, {"order": "44", "text": "S. Kawaguchi, P. K. Garg, M. Matsushita, K. Inoue, \"Mudablue: An automatic categorization system for open source repositories\", <em>Journal of Systems and Software</em>, vol. 79, no. 7, pp. 939-953, 2006.", "title": "Mudablue: An automatic categorization system for open source repositories", "context": [{"sec": "sec4", "text": "This task aims to classify code fragments by their functionalities, which is useful for program understanding and maintenance [2], [44], [45].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1016/j.jss.2005.06.044", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Mudablue%3A+An+automatic+categorization+system+for+open+source+repositories&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref44"}, {"order": "45", "text": "M. Linares-V\u00e1squez, C. McMillan, D. Poshyvanyk, M. Grechanik, \"On using machine learning to automatically classify software applications into domain categories\", <em>Empirical Software Engineering</em>, vol. 19, no. 3, pp. 582-618, 2014.", "title": "On using machine learning to automatically classify software applications into domain categories", "context": [{"sec": "sec4", "text": "This task aims to classify code fragments by their functionalities, which is useful for program understanding and maintenance [2], [44], [45].", "part": "1"}, {"sec": "sec6a", "text": " Based on the statistical and machine learning methods, the n-gram model [1] and SVM [45] are used for classifying source code authorship and domains.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/s10664-012-9230-z", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+using+machine+learning+to+automatically+classify+software+applications+into+domain+categories&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref45"}, {"order": "46", "text": "D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, 2014.", "title": "Adam: A method for stochastic optimization", "context": [{"sec": "sec4", "text": " We use AdaMax [46] in this paper because it is computationally efficient.", "part": "1"}, {"sec": "sec5b", "text": " We use the optimizer AdaMax [46] with learning rate 0.002 for training.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Adam%3A+A+method+for+stochastic+optimization&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref46"}, {"order": "47", "text": "J. Svajlenko, J. F. Islam, I. Keivanloo, C. K. Roy, M. M. Mia, \"Towards a big data curated benchmark of inter-project code clones\", <em>Software Maintenance and Evolution (ICSME) 2014 IEEE International Conference</em>, pp. 476-480, 2014.", "title": "Towards a big data curated benchmark of inter-project code clones", "context": [{"sec": "sec5a", "text": " [47] for evaluating code clone detection tools.", "part": "1"}, {"sec": "sec5c2", "text": " For BCB, the similarity of clone pairs is defined as the average result of line-based and token-based metrics [47].", "part": "1"}, {"sec": "sec5d", "text": " In BCB Type-4, false clone pairs share syntactical similarity as well, which is validated to be coincidental [47] and is challenging to be distinguished.", "part": "1"}, {"sec": "sec7", "text": " However, BigCloneBench includes code snippets of real-world Java repositories from SourceForge [47], which reduces this threat.", "part": "1"}], "links": {"documentLink": "/document/6976121", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6976121", "abstract": "Recently, new applications of code clone detection and search have emerged that rely upon clones detected across thousands of software systems. Big data clone detection and search algorithms have been proposed as an embedded part of these new applications. However, there exists no previous benchmark data for evaluating the recall and precision of these emerging techniques. In this paper, we present a Big Data clone detection benchmark that consists of known true and false positive clones in a Bi...", "pdfSize": "383KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Towards+a+big+data+curated+benchmark+of+inter-project+code+clones&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref47"}, {"order": "48", "text": "A. Charpentier, J.-R. Falleri, D. Lo, L. R\u00e9veill\u00e8re, \"An empirical assessment of bellon's clone benchmark\", <em>Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering</em>, pp. 20, 2015.", "title": "An empirical assessment of bellon's clone benchmark", "context": [{"sec": "sec5a", "text": " As benchmarks, the two datasets have been used by many researchers concerning on code similarity [48], [49] and clone detection [5], [6].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2745802.2745821", "abstract": "Context: Clone benchmarks are essential to the assessment and improvement of clone detection tools and algorithms. Among existing benchmarks, Bellon&#39;s benchmark is widely used by the research community. However, a serious threat to the validity of this benchmark is that reference clones it contains have been manually validated by Bellon alone. Other persons may disagree with Bellon&#39;s judgment. Objective: In this paper, we perform an empirical assessment of Bellon&#39;s benchmark. Method: We seek the...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=An+empirical+assessment+of+bellon%27s+clone+benchmark&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref48"}, {"order": "49", "text": "P. Accioly, P. Borba, G. Cavalcanti, \"Understanding semi-structured merge conflict characteristics in open-source java projects\", <em>Empirical Software Engineering</em>, pp. 1-35, 2017.", "title": "Understanding semi-structured merge conflict characteristics in open-source java projects", "context": [{"sec": "sec5a", "text": " As benchmarks, the two datasets have been used by many researchers concerning on code similarity [48], [49] and clone detection [5], [6].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Understanding+semi-structured+merge+conflict+characteristics+in+open-source+java+projects&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref49"}, {"order": "50", "text": "Y. Kim, \"Convolutional neural networks for sentence classification\", <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pp. 1746-1751, 2014.", "title": "Convolutional neural networks for sentence classification", "context": [{"sec": "sec5c1", "text": " Apart from the state-of-the-art model TBCNN [2], we also take into account of traditional and other neural network based approaches including SVMs with statistical features, TextCNN [50], LSTM [51], LSCNN [52] and PDG-based Graph embedding approaches [25], [26] as follows:\n\n\n\u2022\nSVMs.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.3115/v1/D14-1181", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Convolutional+neural+networks+for+sentence+classification&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref50"}, {"order": "51", "text": "W. Zaremba, I. Sutskever, Learning to execute, 2014.", "title": "Learning to execute", "context": [{"sec": "sec5c1", "text": " Apart from the state-of-the-art model TBCNN [2], we also take into account of traditional and other neural network based approaches including SVMs with statistical features, TextCNN [50], LSTM [51], LSCNN [52] and PDG-based Graph embedding approaches [25], [26] as follows:\n\n\n\u2022\nSVMs.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Learning+to+execute&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref51"}, {"order": "52", "text": "X. Huo, M. Li, \"Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code\", <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em>, pp. 1909-1915, 2017.", "title": "Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code", "context": [{"sec": "sec5c1", "text": " Apart from the state-of-the-art model TBCNN [2], we also take into account of traditional and other neural network based approaches including SVMs with statistical features, TextCNN [50], LSTM [51], LSCNN [52] and PDG-based Graph embedding approaches [25], [26] as follows:\n\n\n\u2022\nSVMs.", "part": "1"}, {"sec": "sec5c1", "text": " Originally proposed for bug location [52], LSCNN extracts program features with CNN for statement embedding and uses LSTM for statement sequences.\n\n\n\u2022\nPDG based Graph Embedding.", "part": "1"}, {"sec": "sec5c1", "text": " Originally proposed for bug location [52], LSCNN extracts program features with CNN for statement embedding and uses LSTM for statement sequences.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.24963/ijcai.2017/265", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Enhancing+the+unified+features+to+locate+buggy+files+by+exploiting+the+sequential+nature+of+source+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref52"}, {"order": "53", "text": "Y. Li, D. Tarlow, M. Brockschmidt, R. Zemel, Gated graph sequence neural networks, 2015.", "title": "Gated graph sequence neural networks", "context": [{"sec": "sec5c1", "text": " Most recently some studies [25], [26] construct program graphs by considering control flow and data flow dependencies, and adopt graph embedding techniques such as HOPE [24] and Gated Graph Neural Network (GGNN) [53] for code representation.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Gated+graph+sequence+neural+networks&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref53"}, {"order": "54", "text": "C. K. Roy, J. R. Cordy, \"A survey on software clone detection research\", <em>Queens School of Computing TR</em>, vol. 541, no. 115, pp. 64-68, 2007.", "title": "A survey on software clone detection research", "context": [{"sec": "sec5c2", "text": "There are generally four different types of code clones [54].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+survey+on+software+clone+detection+research&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref54"}, {"order": "55", "text": "L. Jiang, G. Misherghi, Z. Su, S. Glondu, \"DECKARD: Scalable and accurate tree-based detection of code clones\", <em>Proceedings of the 29th International Conference on Software Engineering</em>, pp. 96-105, 2007.", "title": "DECKARD: Scalable and accurate tree-based detection of code clones", "context": [{"sec": "sec5c2", "text": " Since other traditional clone detection methods like DECKARD [55] and common neural models such as doc2Vec88https://radimrehurek.com/gensim/models/doc2vec.html. have been compared in RAE and CDLH, we omit them in our experiment.", "part": "1"}, {"sec": "sec6a", "text": " Besides the lexical information, Deckard [55] enriches programs with some syntax-structured information for clone detection as well.", "part": "1"}], "links": {"documentLink": "/document/4222572", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=4222572", "abstract": "Detecting code clones has many software engineering applications. Existing approaches either do not scale to large code bases or are not robust against minor code modifications. In this paper, we present an efficient algorithm for identifying similar subtrees and apply it to tree representations of source code. Our algorithm is based on a novel characterization of subtrees with numerical vectors in the Euclidean space Rnmiddot and an efficient algorithm to cluster these vectors w.r.t. the Euclid...", "pdfSize": "824KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=DECKARD%3A+Scalable+and+accurate+tree-based+detection+of+code+clones&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref55"}, {"order": "56", "text": "J. I. Maletic, A. Marcus, \"Supporting program comprehension using semantic and structural information\", <em>Proceedings of the 23rd International Conference on Software Engineering</em>, pp. 103-112, 2001.", "title": "Supporting program comprehension using semantic and structural information", "context": [{"sec": "sec6a", "text": " [56] adopts LSI to identify semantic similarities of code fragments, and the cohesion of classes in software is evaluated by LDA [15].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Supporting+program+comprehension+using+semantic+and+structural+information&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref56"}, {"order": "57", "text": "M. Allamanis, E. T. Barr, P. Devanbu, C. Sutton, A survey of machine learning for big code and naturalness, 2017.", "title": "A survey of machine learning for big code and naturalness", "context": [{"sec": "sec6a", "text": "Recently deep learning based approaches have attracted much attention to learn distributed representation of source code [57].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+survey+of+machine+learning+for+big+code+and+naturalness&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref57"}, {"order": "58", "text": "V. Raychev, M. Vechev, E. Yahav, \"Code completion with statistical language models\", <em>Acm Sigplan Notices</em>, vol. 49, no. 6, pp. 419-428, 2014.", "title": "Code completion with statistical language models", "context": [{"sec": "sec6a", "text": " [58] adopts RNN and n-gram model for code completion.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Code+completion+with+statistical+language+models&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref58"}, {"order": "59", "text": "M. Allamanis, E. T. Barr, C. Bird, C. Sutton, \"Suggesting accurate method and class names\", <em>Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering</em>, pp. 38-49, 2015.", "title": "Suggesting accurate method and class names", "context": [{"sec": "sec6a", "text": " [59] uses a neural context model to suggest method and class names.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2786805.2786849", "abstract": "Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilisti...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Suggesting+accurate+method+and+class+names&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref59"}, {"order": "60", "text": "S. Wang, T. Liu, L. Tan, \"Automatically learning semantic features for defect prediction\", <em>Proceedings of the 38th International Conference on Software Engineering</em>, pp. 297-308, 2016.", "title": "Automatically learning semantic features for defect prediction", "context": [{"sec": "sec6a", "text": " For defect prediction, semantic features are extracted from source code by a deep belief network [60].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2884781.2884804", "abstract": "Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models. To bridge the ...", "pdfSize": "1876KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Automatically+learning+semantic+features+for+defect+prediction&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref60"}, {"order": "61", "text": "M. Pradel, K. Sen, \"DeepBugs: A learning approach to name-based bug detection\", <em>Proc. ACM Program. Lang.</em>, vol. 2, no. OOPSLA, pp. 147:1-147:25, Oct. 2018.", "title": "DeepBugs: A learning approach to name-based bug detection", "context": [{"sec": "sec6a", "text": " DeepBugs [61] represents code via word2vec for detecting name-based bugs.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/3276517", "abstract": "Natural language elements in source code, e.g., the names of variables and functions, convey useful information. However, most existing bug detection tools ignore this information and therefore miss some classes of bugs. The few existing name-based bug detection approaches reason about names on a syntactic level and rely on manually designed and tuned algorithms to detect bugs. This paper presents DeepBugs, a learning approach to name-based bug detection, which reasons about names based on a sem...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=DeepBugs%3A+A+learning+approach+to+name-based+bug+detection&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref61"}, {"order": "62", "text": "G. Zhao, J. Huang, \"DeepSim: Deep learning code functional similarity\", <em>Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</em>, pp. 141-151, 2018.", "title": "DeepSim: Deep learning code functional similarity", "context": [{"sec": "sec6a", "text": " DeepSim [62] encodes code control flow and data flow into a semantic matrix for measuring code functional similarity.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/3236024.3236068", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=DeepSim%3A+Deep+learning+code+functional+similarity&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref62"}, {"order": "63", "text": "A. N. Lam, A. T. Nguyen, H. A. Nguyen, T. N. Nguyen, \"Combining deep learning with information retrieval to localize buggy files for bug reports (n)\", <em>Automated Software Engineering (ASE) 2015 30th IEEE/ACM International Conference</em>, pp. 476-481, 2015.", "title": "Combining deep learning with information retrieval to localize buggy files for bug reports (n)", "context": [{"sec": "sec6b", "text": " [63] combines deep neural network with IR technique to recommend potential buggy files.", "part": "1"}], "links": {"documentLink": "/document/7372035", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=7372035", "abstract": "Bug localization refers to the automated process of locating the potential buggy files for a given bug report. To help developers focus their attention to those files is crucial. Several existing automated approaches for bug localization from a bug report face a key challenge, called lexical mismatch, in which the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. This paper presents a novel approach that uses deep neural network (DNN) ...", "pdfSize": "258KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Combining+deep+learning+with+information+retrieval+to+localize+buggy+files+for+bug+reports+%28n%29&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref63"}, {"order": "64", "text": "B. Xu, D. Ye, Z. Xing, X. Xia, G. Chen, S. Li, \"Predicting semantically linkable knowledge in developer online forums via convolutional neural network\", <em>Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering</em>, pp. 51-62, 2016.", "title": "Predicting semantically linkable knowledge in developer online forums via convolutional neural network", "context": [{"sec": "sec6b", "text": " [64] adopts word embeddings and convolutional neural network to predict the related questions in StackOverflow.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2970276.2970357", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Predicting+semantically+linkable+knowledge+in+developer+online+forums+via+convolutional+neural+network&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref64"}, {"order": "65", "text": "J. Guo, J. Cheng, J. Cleland-Huang, \"Semantically enhanced software traceability using deep learning techniques\", <em>Proceedings of the 39th International Conference on Software Engineering</em>, pp. 3-14, 2017.", "title": "Semantically enhanced software traceability using deep learning techniques", "context": [{"sec": "sec6b", "text": " [65] proposes a RNN based neural network to generate trace links.", "part": "1"}], "links": {"documentLink": "/document/7985645", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=7985645", "abstract": "In most safety-critical domains the need for traceability is prescribed by certifying bodies. Trace links are generally created among requirements, design, source code, test cases and other artifacts, however, creating such links manually is time consuming and error prone. Automated solutions use information retrieval and machine learning techniques to generate trace links, however, current techniques fail to understand semantics of the software artifacts or to integrate domain knowledge into th...", "pdfSize": "1398KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Semantically+enhanced+software+traceability+using+deep+learning+techniques&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref65"}, {"order": "66", "text": "X. Gu, H. Zhang, S. Kim, \"Deep code search\", <em>Proceedings of the 2018 40th International Conference on Software Engineering (ICSE 2018)</em>, 2018.", "title": "Deep code search", "context": [{"sec": "sec6b", "text": " A joint embedding model is used in code search to map source code and natural language descriptions into a unified vector space for evaluating semantics similarity [66].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/3180155.3180167", "abstract": "To implement a program functionality, developers can reuse previously written code snippets by searching through a large-scale codebase. Over the years, many code search tools have been proposed to help developers. The existing approaches often treat source code as textual documents and utilize information retrieval models to retrieve relevant code snippets that match a given query. These approaches mainly rely on the textual similarity between source code and natural language query. They lack a...", "pdfSize": "677KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Deep+code+search&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref66"}], "pdfLink": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812062", "articleId": "8812062", "startPage": "783", "endPage": "794", "pubLink": "https://ieeexplore.ieee.org/xpl/conhome/8790403/proceeding", "issueLink": "https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8811891", "publisher": "IEEE", "confLoc": "Montreal, QC, Canada, Canada", "chronDate": "25-31 May 2019", "metrics": {"citationCountPaper": 1, "citationCountPatent": 0, "totalDownloads": 390}}
{"title": "Balancing Soundness and Efficiency for Practical Testing of Configurable Systems", "authors": [{"name": "Sabrina Souto", "affiliation": "State Univ. of Paraiba, Para\u00edba, Brazil", "firstName": "Sabrina", "lastName": "Souto", "id": "37086185515"}, {"name": "Marcelo D'Amorim", "affiliation": "Fed. Univ. of Pernambuco, Recife, Brazil", "firstName": "Marcelo", "lastName": "D'Amorim", "id": "37831778900"}, {"name": "Rohit Gheyi", "affiliation": "Fed. Univ. of Campina Grande, Campina Grande, Brazil", "firstName": "Rohit", "lastName": "Gheyi", "id": "37391828700"}], "abstract": "Testing configurable systems is important and challenging due to the enormous space of configurations where errors can hide. Existing approaches to test these systems are often costly or unreliable. This paper proposes S-SPLat, a technique that combines heuristic sampling with symbolic search to obtain both breadth and depth in the exploration of the configuration space. S-SPLat builds on SPLat, our previously developed technique, that explores all reachable configurations from tests. In contrast to its predecessor, S-SPLat sacrifices soundness in favor of efficiency. We evaluated our technique on eight software product lines of various sizes and on a large configurable system - GCC. Considering the results for GCC, S-SPLat was able to reproduce all five bugs that we previously found in a previous study with SPLat but much faster and it was able to find two new bugs in a recent release of GCC. Results suggest that it is preferable to use a combination of simple heuristics to drive the symbolic search as opposed to a single heuristic. S-SPLat and our experimental infrastructure are publicly available.", "keywords": [{"type": "IEEE Keywords", "kwd": ["Testing", "Computer bugs", "Software product lines", "Complexity theory", "Reliability", "Space exploration"]}, {"type": "INSPEC: Controlled Indexing", "kwd": ["program testing", "software product lines"]}, {"type": "INSPEC: Non-Controlled Indexing", "kwd": ["configurable system testing", "S-SPLat technique", "heuristic sampling", "symbolic search", "configuration space", "software product lines", "GCC"]}, {"type": "Author Keywords ", "kwd": ["sampling", "testing", "configuration"]}], "publication": "2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)", "doi": "10.1109/ICSE.2017.64", "ref": [{"order": "1", "text": "<em>Configuration error brings down the Azure cloud platform</em>,  [online]  Available: http://www.evolven.com/blog/configuration-error-brings-down-the-azure-cloud-platform.html.", "title": "Configuration error brings down the Azure cloud platform", "context": [{"sec": "sec1", "text": " Some of these errors have been widely publicized in the media given the volume of users or data they affected [1], [3], [23].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Configuration+error+brings+down+the+Azure+cloud+platform&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref1"}, {"order": "2", "text": "<em>DejaGnu</em>,  [online]  Available: http://www.gnu.org/software/dejagnu/.", "title": "DejaGnu", "context": [{"sec": "sec5b1a", "text": "GCC uses DejaGnu [2] as testing framework.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=DejaGnu&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref2"}, {"order": "3", "text": "<em>DNS misconfiguration</em>,  [online]  Available: http://www.circleid.com/posts/misconfiguration_brings_down_entire_se_domain_in_sweden.", "title": "DNS misconfiguration", "context": [{"sec": "sec1", "text": " Some of these errors have been widely publicized in the media given the volume of users or data they affected [1], [3], [23].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=DNS+misconfiguration&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref3"}, {"order": "4", "text": "<em>Firefox web browser</em>,  [online]  Available: http://hg.mozilla.org.", "title": "Firefox web browser", "context": [{"sec": "sec1", "text": " The Firefox web browser [4], the Linux kernel [9], the GCC compiler infrastructure [5], and the deals-recommendation web service Groupon [8] are some well-known examples of configurable systems.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Firefox+web+browser&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref4"}, {"order": "5", "text": "<em>GCC compiler infrastructure</em>,  [online]  Available: http://gcc.gnu.org.", "title": "GCC compiler infrastructure", "context": [{"sec": "sec1", "text": " The Firefox web browser [4], the Linux kernel [9], the GCC compiler infrastructure [5], and the deals-recommendation web service Groupon [8] are some well-known examples of configurable systems.", "part": "1"}, {"sec": "sec5", "text": " In the second scenario, we evaluated the techniques on a large configurable system (GCC [5]) manifesting different characteristics compared to SPLs.", "part": "1"}, {"sec": "sec5b", "text": "We also evaluated S-SPLat against the GNU Compiler Collection (GCC) [5], a large configurable system with hundreds of options [6].", "part": "1"}, {"sec": "sec5d", "text": " One limitation of the study relates to the fact that SPLat currently only supports systems with dynamically bound feature variables (e.g., Groupon web [8], [29], and GCC [5]).", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=GCC+compiler+infrastructure&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref5"}, {"order": "6", "text": "<em>GCC Options</em>,  [online]  Available: https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html.", "title": "GCC Options", "context": [{"sec": "sec5b", "text": "We also evaluated S-SPLat against the GNU Compiler Collection (GCC) [5], a large configurable system with hundreds of options [6].", "part": "1"}, {"sec": "sec5b1b", "text": "We limited the number of options to analyze (see [6]) given the long execution times found in some test cases.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=GCC+Options&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref6"}, {"order": "7", "text": "<em>GCC releases</em>,  [online]  Available: https://gcc.gnu.org/releases.html.", "title": "GCC releases", "context": [{"sec": "sec5b", "text": " In one setup we measured ability to find test failures in the GCC release 6.1 [7] (Section V-B1).", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=GCC+releases&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref7"}, {"order": "8", "text": "<em>Groupon</em>,  [online]  Available: http://groupon.com.", "title": "Groupon", "context": [{"sec": "sec1", "text": " The Firefox web browser [4], the Linux kernel [9], the GCC compiler infrastructure [5], and the deals-recommendation web service Groupon [8] are some well-known examples of configurable systems.", "part": "1"}, {"sec": "sec5d", "text": " One limitation of the study relates to the fact that SPLat currently only supports systems with dynamically bound feature variables (e.g., Groupon web [8], [29], and GCC [5]).", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Groupon&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref8"}, {"order": "9", "text": "<em>Linux kernel</em>,  [online]  Available: http://www.kernel.org.", "title": "Linux kernel", "context": [{"sec": "sec1", "text": " The Firefox web browser [4], the Linux kernel [9], the GCC compiler infrastructure [5], and the deals-recommendation web service Groupon [8] are some well-known examples of configurable systems.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Linux+kernel&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref9"}, {"order": "10", "text": "<em>Soundiness webpage</em>,  [online]  Available: http://soundiness.org/.", "title": "Soundiness webpage", "context": [{"sec": "sec3", "text": " The intuition is that the use of heuristics can provide a better balance between cost and reliability and that balance is essential for practicality in this domain [10], [34], [36].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Soundiness+webpage&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref10"}, {"order": "11", "text": "Iago Abal, Claus Brabrand, Andrzej Wasowski, \"42 variability bugs in the Linux kernel: A qualitative analysis\", <em>Proceedings of the Automated Software Engineering</em>, pp. 421-432, 2014.", "title": "42 variability bugs in the Linux kernel: A qualitative analysis", "context": [{"sec": "sec1", "text": " Unfortunately, configuration-related errors are not rare [11], [19], [25], [39].", "part": "1"}, {"sec": "sec1", "text": "We analyzed S-SPLat with five basic heuristics that have demonstrated promising results in different studies [11], [38] and eleven combinations of these basic heuristics.", "part": "1"}, {"sec": "sec1", "text": " Overall, considering our experimental setup, results suggest that it is preferable to combine some heuristics that demand a relatively low number of test requirements (e.g., one-enabled and one-disabled [11]) than using heuristics that solicit more test requirements (e.g., pairwise [52]).", "part": "1"}, {"sec": "sec2b", "text": "Among the various sampling heuristics proposed in the literature related to testing configurable systems, we considered those that have been recently evaluated and are applicable in our context [11], [38].", "part": "1"}, {"sec": "sec5b4", "text": " These results confirm previous observations that configuration-related errors are often manifested in configurations involving a small number of input options [11], [19], [31], [39].", "part": "1"}, {"sec": "sec6a1b", "text": " [11] analyze the Linux kernel software repository to study configuration-related faults fixed by developers.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2642937.2642990", "abstract": "Feature-sensitive verification pursues effective analysis of the exponentially many variants of a program family. However, researchers lack examples of concrete bugs induced by variability, occurring in real large-scale systems. Such a collection of bugs is a requirement for goal-oriented research, serving to evaluate tool implementations of feature-sensitive analyses by testing them on real bugs. We present a qualitative study of 42 variability bugs collected from bug-fixing commits to the Linu...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=42+variability+bugs+in+the+Linux+kernel%3A+A+qualitative+analysis&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref11"}, {"order": "12", "text": "Sven Apel, Don Batory, Christian K\u00e4stner, Gunter Saake, Feature-Oriented Software Product Lines: Concepts and Implementation, Springer-Verlag, 2013.", "title": "Feature-Oriented Software Product Lines: Concepts and Implementation", "context": [{"sec": "sec2a", "text": " We make no distinction between Software Product Lines (SPLs) [12], [15] and other kinds of configurable systems.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/978-3-642-37521-7", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Feature-Oriented+Software+Product+Lines%3A+Concepts+and+Implementation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref12"}, {"order": "13", "text": "Sven Apel, Dirk Beyer, \"Feature cohesion in software product lines: An exploratory study\", <em>Proceedings of the International Conference on Software Engineering</em>, pp. 421-430, 2011.", "title": "Feature cohesion in software product lines: An exploratory study", "context": [{"sec": "sec5a1a", "text": "We selected eight SPLs previously used in other studies [13], [26], [32], [40].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/1985793.1985851", "abstract": "Software product lines gain momentum in research and industry. Many product-line approaches use features as a central abstraction mechanism. Feature-oriented software development aims at encapsulating features in cohesive units to support program comprehension, variability, and reuse. Surprisingly, not much is known about the characteristics of cohesion in feature-oriented product lines, although proper cohesion is of special interest in product-line engineering due to its focus on variability a...", "pdfSize": "630KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Feature+cohesion+in+software+product+lines%3A+An+exploratory+study&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref13"}, {"order": "14", "text": "Sven Apel, Alexander von Rhein, Philipp Wendler, Armin Groblinger, Dirk Beyer, \"Strategies for product-line verification: case studies and experiments\", <em>Proceedings of the InternationalConference on Software Engineering</em>, pp. 482-491, 2013.", "title": "Strategies for product-line verification: case studies and experiments", "context": [{"sec": "sec6a1b", "text": " [14] have developed a model-checking tool for C and Java product lines.", "part": "1"}], "links": {"abstract": "Product-line technology is increasingly used in mission-critical and safety-critical applications. Hence, researchers are developing verification approaches that follow different strategies to cope with the specific properties of product lines. While the research community is discussing the mutual strengths and weaknesses of the different strategies\u2014mostly at a conceptual level\u2014there is a lack of evidence in terms of case studies, tool implementations, and experiments. We have collected and prep...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Strategies+for+product-line+verification%3A+case+studies+and+experiments&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref14"}, {"order": "15", "text": "Don Batory, Clay Johnson, Bob MacDonald, Dale von Heeder, \"Achieving extensibility through product-lines and domain-specific languages: A case study\", <em>ACM Transactions on Software Engineering and Methodology (TOSEM)</em>, vol. 11, no. 2, pp. 191-214, 2002.", "title": "Achieving extensibility through product-lines and domain-specific languages: A case study", "context": [{"sec": "sec2a", "text": " We make no distinction between Software Product Lines (SPLs) [12], [15] and other kinds of configurable systems.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/505145.505147", "abstract": "This is a case study in the use of product-line architectures (PLAs) and domain-specific languages (DSLs) to design an extensible command-and-control simulator for Army fire support. The reusable components of our PLA are layers or &#34;aspects&#34; whose addition or removal simultaneously impacts the source code of multiple objects in multiple, distributed programs. The complexity of our component specifications is substantially reduced by using a DSL for defining and refining state machines, abstracti...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Achieving+extensibility+through+product-lines+and+domain-specific+languages%3A+A+case+study&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref15"}, {"order": "16", "text": "Abu Syed Md Masud Ching-Lai Hwang, Multiple Objective Decision Making \u2014 Methods and Applications: a state-of-the-art survey, Springer-Verlag, vol. 164, 1979.", "title": "Multiple Objective Decision Making \u2014 Methods and Applications: a state-of-the-art survey", "context": [{"sec": "sec5a4", "text": " To facilitate visualization, the plots show the Pareto fronts [16] of measurements as solid circles.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Multiple+Objective+Decision+Making+%E2%80%94+Methods+and+Applications%3A+a+state-of-the-art+survey&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref16"}, {"order": "17", "text": "Myra B. Cohen, Peter B. Gibbons, Warwick B. Mugridge, Charles J. Colbourn, \"Constructing test suites for interaction testing\", <em>Proceedings of the International Conference on Software Engineering</em>, pp. 38-48, 2003.", "title": "Constructing test suites for interaction testing", "context": [{"sec": "sec1", "text": "Combinatorial Interaction Testing (CIT) [51] has been popularized to balance probability of finding configuration errors (i.e., efficacy) and efficiency [17], [30], [31], [38], [42].", "part": "1"}], "links": {"documentLink": "/document/1201186", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=1201186", "abstract": "Software system faults are often caused by unexpected interactions among components. Yet the size of a test suite required to test all possible combinations of interactions can be prohibitive in even a moderately sized project. Instead, we may use pairwise or t-way testing to provide a guarantee that all pairs or t-way combinations of components are tested together This concept draws on methods used in statistical testing for manufacturing and has been extended to software system testing. A cove...", "pdfSize": "371KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Constructing+test+suites+for+interaction+testing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref17"}, {"order": "18", "text": "Marcelo d'Amorim, Steven Lauterburg, Darko Marinov, \"Delta execution for efficient state-space exploration of object-oriented programs\", <em>IEEE Transactions on Software Engineering</em>, vol. 34, no. 5, pp. 597-613, 2008.", "title": "Delta execution for efficient state-space exploration of object-oriented programs", "context": [{"sec": "sec6a1a", "text": " Multi-execution approaches, such as DeltaExecution [18], SharedExecution [28] and Varex [41], execute a given test simultaneously against sets of configurations; they leverage the similarities that exist across configurations to reduce the total number of paths explored in a test and the overall amount of computation.", "part": "1"}, {"sec": "sec6a1a", "text": " On the one hand, building (and maintaining) such interpreters is challenging, especially for statically-typed languages [18], [28], [45].", "part": "1"}], "links": {"documentLink": "/document/4528965", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=4528965", "abstract": "We present Delta execution, a technique that speeds up state-space exploration of object-oriented programs. State-space exploration is the essence of model checking and an increasingly popular approach for automating test generation. A key issue in exploration of object-oriented programs is handling the program state, in particular the heap. We exploit the fact that many execution paths in state-space exploration partially overlap. Delta execution simultaneously operates on several states/heaps ...", "pdfSize": "4878KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Delta+execution+for+efficient+state-space+exploration+of+object-oriented+programs&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref18"}, {"order": "19", "text": "Brady J. Garvin, Myra B. Cohen, \"Feature interaction faults revisited: An exploratory study\", <em>Proceedings of the InternationalSymposium on Software Reliability Engineering</em>, pp. 90-99, 2011.", "title": "Feature interaction faults revisited: An exploratory study", "context": [{"sec": "sec1", "text": " Unfortunately, configuration-related errors are not rare [11], [19], [25], [39].", "part": "1"}, {"sec": "sec5b4", "text": " These results confirm previous observations that configuration-related errors are often manifested in configurations involving a small number of input options [11], [19], [31], [39].", "part": "1"}], "links": {"abstract": "While a large body of research is dedicated to testing for feature interactions in configurable software, there has been little work that examines what constitutes such a fault at the code level. In consequence, we do not know how prevalent real interaction faults are in practice, what a typical interaction fault looks like in code, how to seed interaction faults, or whether current interaction testing techniques are effective at finding the faults they aim to detect. We make a first step in thi...", "pdfSize": "205KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Feature+interaction+faults+revisited%3A+An+exploratory+study&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref19"}, {"order": "20", "text": "\"Preparing Testcases\", <em>HowToPrepare ATestcase</em>,  [online]  Available: http://gcc.gnu.org/wiki/.", "title": "Preparing Testcases", "context": [{"sec": "sec5b1a", "text": " For example, compilation tasks include preprocessing, compiling, assembling, linking, and running code [20].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Preparing+Testcases&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref20"}, {"order": "21", "text": "<em>GrammaTech. Hybrid concolic execution</em>,  [online]  Available: http://blogs.grammatech.com/hybrid-concolic-execution-part-l.", "title": "GrammaTech. Hybrid concolic execution", "context": [{"sec": "sec1", "text": " Our approach is similar in spirit to hybrid concolic execution [21], [36]; (implementation) we implemented S-SPLat, a variant of our previously-developed technique SPLat [29].", "part": "1"}, {"sec": "sec6a1d", "text": " Hybrid concolic execution [21], [36] is a variant of concolic execution that aims to explore the state space more broadly and deeply compared to a regular concolic execution, which conceptually can get stuck (e.g., as observed with saturation in coverage) in dense branches of the symbolic tree.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=GrammaTech.+Hybrid+concolic+execution&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref21"}, {"order": "22", "text": "Michaela Greiler, Arie van Deursen, Margaret-Anne Storey, \"Test confessions: A study of testing practices for plug-in systems\", <em>Proceedings of the InternationalConference on Software Engineering</em>, pp. 244-254, 2012.", "title": "Test confessions: A study of testing practices for plug-in systems", "context": [{"sec": "sec1", "text": " In another limit, testing against one (default) configuration, albeit popular, leads to high chances of escaped defects [22], [35].", "part": "1"}], "links": {"documentLink": "/document/6227189", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6227189", "abstract": "Testing plug-in-based systems is challenging due to complex interactions among many different plug-ins, and variations in version and configuration. The objective of this paper is to increase our understanding of what testers and developers think and do when it comes to testing plug-in-based systems. To that end, we conduct a qualitative (grounded theory) study, in which we interview 25 senior practitioners about how they test plug-in applications based on the Eclipse plug-in architecture. The o...", "pdfSize": "715KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Test+confessions%3A+A+study+of+testing+practices+for+plug-in+systems&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref22"}, {"order": "23", "text": "Robert Johnson, <em>More details on today's outage</em>,  [online]  Available: https://www.facebook.comlnotes/facebook-engineering/more-details-on-todaysoutage/431441338919.", "title": "More details on today's outage", "context": [{"sec": "sec1", "text": " Some of these errors have been widely publicized in the media given the volume of users or data they affected [1], [3], [23].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=More+details+on+today%27s+outage&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref23"}, {"order": "24", "text": "Kyo Kang, Sholom Cohen, James Hess, William Nowak, Spencer Peterson, \"Feature-Oriented Domain Analysis (FODA) Feasibility Study\", <em>Technical Report CMU/SEI-90-TR-21</em>, 1990.", "title": "Feature-Oriented Domain Analysis (FODA) Feasibility Study", "context": [{"sec": "sec2a", "text": "A feature model (FM) [24] distinguishes which combinations of variables are legal from those that are not.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.21236/ADA235785", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Feature-Oriented+Domain+Analysis+%28FODA%29+Feasibility+Study&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref24"}, {"order": "25", "text": "Christian K\u00e4stner, Paolo G. Giarrusso, Tillmann Rendel, Sebastian Erdweg, Klaus Ostermann, Thorsten Berger, \"Variability-aware parsing in the presence of lexical macros and conditional compilation\", <em>Proceedings of the Object-Oriented Programing Systems Languages and Applications</em>, pp. 805-824, 2011.", "title": "Variability-aware parsing in the presence of lexical macros and conditional compilation", "context": [{"sec": "sec1", "text": " Unfortunately, configuration-related errors are not rare [11], [19], [25], [39].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2048066.2048128", "abstract": "In many projects, lexical preprocessors are used to manage different variants of the project (using conditional compilation) and to define compile-time code transformations (using macros). Unfortunately, while being a simple way to implement variability, conditional compilation and lexical macros hinder automatic analysis, even though such analysis is urgently needed to combat variability-induced complexity. To analyze code with its variability, we need to parse it without preprocessing it. Howe...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Variability-aware+parsing+in+the+presence+of+lexical+macros+and+conditional+compilation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref25"}, {"order": "26", "text": "Chang Hwan Peter Kim, Don S. Batory, Sarfraz Khurshid, \"Reducing combinatorics in testing product lines\", <em>Proceedings of the Aspect-Oriented Software Development</em>, pp. 57-68, 2011.", "title": "Reducing combinatorics in testing product lines", "context": [{"sec": "sec2b", "text": "Notepad is a visual text editor, implemented as a configurable system, that has been previously used in related studies [26], [27], [29].", "part": "1"}, {"sec": "sec5a1a", "text": "We selected eight SPLs previously used in other studies [13], [26], [32], [40].", "part": "1"}, {"sec": "sec5a2", "text": " To note that previous studies used similar metrics for similar reasons [26], [38].", "part": "1"}, {"sec": "sec6a1c", "text": " [26] previously developed a static analysis to determine which features are relevant to the outcome of a test.", "part": "1"}, {"sec": "sec6a1c", "text": " [26].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Reducing+combinatorics+in+testing+product+lines&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref26"}, {"order": "27", "text": "Chang Hwan Peter Kim, Eric Bodden, Don S. Batory, Sarfraz Khurshid, \"Reducing configurations to monitor in a software product line\", <em>Proceedings of the Runtime Verification</em>, pp. 285-299, 2010.", "title": "Reducing configurations to monitor in a software product line", "context": [{"sec": "sec2b", "text": "Notepad is a visual text editor, implemented as a configurable system, that has been previously used in related studies [26], [27], [29].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Reducing+configurations+to+monitor+in+a+software+product+line&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref27"}, {"order": "28", "text": "Chang Hwan Peter Kim, Sarfraz Khurshid, Don Batory, \"Shared execution for efficiently testing product lines\", <em>Proceedings of the International Symposium on Software Reliability Engineering</em>, pp. 221-230, 2012.", "title": "Shared execution for efficiently testing product lines", "context": [{"sec": "sec1", "text": "More recently, sound testing techniques have been proposed [28], [29], [33], [41]; they assure that all configuration errors that can be captured with a given test will be captured.", "part": "1"}, {"sec": "sec6a1a", "text": " Multi-execution approaches, such as DeltaExecution [18], SharedExecution [28] and Varex [41], execute a given test simultaneously against sets of configurations; they leverage the similarities that exist across configurations to reduce the total number of paths explored in a test and the overall amount of computation.", "part": "1"}, {"sec": "sec6a1a", "text": " On the one hand, building (and maintaining) such interpreters is challenging, especially for statically-typed languages [18], [28], [45].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Shared+execution+for+efficiently+testing+product+lines&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref28"}, {"order": "29", "text": "Chang Hwan Peter Kim, Darko Marinov, Sarfraz Khurshid, Don Batory, Sabrina Souto, Paulo Barros, Marcelo d'Amorim, \"SPLat: Lightweight dynamic analysis for reducing combinatorics in testing configurable systems\", <em>Proceedings of the Foundations of Software Engineering</em>, pp. 257-267, 2013.", "title": "SPLat: Lightweight dynamic analysis for reducing combinatorics in testing configurable systems", "context": [{"sec": "sec1", "text": "More recently, sound testing techniques have been proposed [28], [29], [33], [41]; they assure that all configuration errors that can be captured with a given test will be captured.", "part": "1"}, {"sec": "sec1", "text": " This is the case, for example, when test execution dynamically accesses a relatively small number of configuration variables [29].", "part": "1"}, {"sec": "sec1", "text": " In this study, we used SPLat [29], [47], [49], a sound technique, previously developed by the authors, that monitors variable accesses in one execution and, based on that, decides which configurations should be executed next.", "part": "1"}, {"sec": "sec1", "text": " Our approach is similar in spirit to hybrid concolic execution [21], [36]; (implementation) we implemented S-SPLat, a variant of our previously-developed technique SPLat [29].", "part": "1"}, {"sec": "sec2b", "text": "Notepad is a visual text editor, implemented as a configurable system, that has been previously used in related studies [26], [27], [29].", "part": "1"}, {"sec": "sec2c", "text": "In a nutshell, SPLat [29] works as follows.", "part": "1"}, {"sec": "sec4", "text": "This section describes S-SPLat (for Sampling with SPLat), a modified version of the SPLat algorithm [29].", "part": "1"}, {"sec": "sec4", "text": " A complete version of SPLat can be found elsewhere [29].", "part": "1"}, {"sec": "sec5d", "text": " One limitation of the study relates to the fact that SPLat currently only supports systems with dynamically bound feature variables (e.g., Groupon web [8], [29], and GCC [5]).", "part": "1"}, {"sec": "sec6a1a", "text": " Single-execution approaches, such as SPLat [29], [49], in contrast, execute a test once for each reachable configuration that they discover while building a decision tree from configuration variables accessed during execution.", "part": "1"}, {"sec": "sec6a1c", "text": " It is important to note that obtaining dynamic reachability information efficiently is the key feature of SPLat [29], which built upon the ideas of Kim et al. [26].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=SPLat%3A+Lightweight+dynamic+analysis+for+reducing+combinatorics+in+testing+configurable+systems&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref29"}, {"order": "30", "text": "D. Richard Kuhn, Raghu N. Kacker, Yu Lei, \"Practical combinatorial testing\", <em>Technical Report SP 800-142</em>, 2010.", "title": "Practical combinatorial testing", "context": [{"sec": "sec1", "text": "Combinatorial Interaction Testing (CIT) [51] has been popularized to balance probability of finding configuration errors (i.e., efficacy) and efficiency [17], [30], [31], [38], [42].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Practical+combinatorial+testing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref30"}, {"order": "31", "text": "D. Richard Kuhn, Dolores R. Wallace, Albert M. Gallo, \"Software fault interactions and implications for software testing\", <em>IEEE Transactions on Software Engineering</em>, vol. 30, no. 6, pp. 418-421, 2004.", "title": "Software fault interactions and implications for software testing", "context": [{"sec": "sec1", "text": "Combinatorial Interaction Testing (CIT) [51] has been popularized to balance probability of finding configuration errors (i.e., efficacy) and efficiency [17], [30], [31], [38], [42].", "part": "1"}, {"sec": "sec5b4", "text": " These results confirm previous observations that configuration-related errors are often manifested in configurations involving a small number of input options [11], [19], [31], [39].", "part": "1"}], "links": {"documentLink": "/document/1321063", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=1321063", "abstract": "Exhaustive testing of computer software is intractable, but empirical studies of software failures suggest that testing can in some cases be effectively exhaustive. We show that software failures in a variety of domains were caused by combinations of relatively few conditions. These results have important implications for testing. If all faults in a system can be triggered by a combination of n or fewer parameters, then testing all n-tuples of parameters is effectively equivalent to exhaustive t...", "pdfSize": "362KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Software+fault+interactions+and+implications+for+software+testing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref31"}, {"order": "32", "text": "Philipp Lengauer, Verena Bitto, Florian Angerer, Paul Gr\u00fcnbacher, Hanspeter Mossenb\u00f6ck, \"Where has all my memory gone?: Determining memory characteristics of product variants using virtual-machine-level monitoring\", <em>Proceedings of the Variability Modelling of Software-Intensive Systems</em>, pp. 13:1-13:8, 2013.", "title": "Where has all my memory gone?: Determining memory characteristics of product variants using virtual-machine-level monitoring", "context": [{"sec": "sec5a1a", "text": "We selected eight SPLs previously used in other studies [13], [26], [32], [40].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2556624.2556628", "abstract": "Non-functional properties such as memory footprint have recently gained importance in software product line research. However, determining the memory characteristics of individual features and product variants is extremely challenging. We present an approach that supports the monitoring of memory characteristics of individual features at the level of Java virtual machines. Our approach provides extensions to Java virtual machines to track memory allocations and deal-locations of individual featu...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Where+has+all+my+memory+gone%3F%3A+Determining+memory+characteristics+of+product+variants+using+virtual-machine-level+monitoring&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref32"}, {"order": "33", "text": "J\u00f6rg Liebig, Alexander von Rhein, Christian K\u00e4stner, Sven Apel, Jens D\u00f6rre, Christian Lengauer, \"Scalable analysis of variable software\", <em>Proceedings of the Foundations of Software Engineering</em>, pp. 81-91, 2013.", "title": "Scalable analysis of variable software", "context": [{"sec": "sec1", "text": "More recently, sound testing techniques have been proposed [28], [29], [33], [41]; they assure that all configuration errors that can be captured with a given test will be captured.", "part": "1"}, {"sec": "sec6a1b", "text": " [33] perform studies to detect the strengths and weaknesses of variability-aware and sampling-based analyses (single configuration, pair-wise and code-coverage).", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2491411.2491437", "abstract": "The advent of variability management and generator technology enables users to derive individual variants from a variable code base based on a selection of desired configuration options. This approach gives rise to the generation of possibly billions of variants that, however, cannot be efficiently analyzed for errors with classic analysis techniques. To address this issue, researchers and practitioners usually apply sampling heuristics. While sampling reduces the analysis effort significantly, ...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Scalable+analysis+of+variable+software&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref33"}, {"order": "34", "text": "Benjamin Livshits, Manu Sridharan, Yannis Smaragdakis, Ond\u0159ej Lhot\u00e1k, J. Nelson Amaral, Bor-Yuh Evan Chang, Samuel Z. Guyer, Uday P. Khedker, Anders M\u00f8ller, Dimitrios Vardoulakis, \"In defense of soundiness: A manifesto\" in Communications of the ACM, vol. 58, no. 2, pp. 44-46, 2015.", "title": "In defense of soundiness: A manifesto", "context": [{"sec": "sec1", "text": " Recently, the static analysis community acknowledged the importance of making (and documenting) conscious unsound design choices in favor of practical soundy solutions [34].", "part": "1"}, {"sec": "sec3", "text": " The intuition is that the use of heuristics can provide a better balance between cost and reliability and that balance is essential for practicality in this domain [10], [34], [36].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2644805", "abstract": "Soundy is the new sound.", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=In+defense+of+soundiness%3A+A+manifesto&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref34"}, {"order": "35", "text": "Ivan do Carmo Machado, John D. Mcgregor, Yguarata Cerqueira Cavalcanti, Eduardo Santana de Almeida, \"On strategies for testing software product lines: A systematic literature review\", <em>Information and Software Technology</em>, vol. 56, no. 10, pp. 1183-1199, 2014.", "title": "On strategies for testing software product lines: A systematic literature review", "context": [{"sec": "sec1", "text": " In another limit, testing against one (default) configuration, albeit popular, leads to high chances of escaped defects [22], [35].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1016/j.infsof.2014.04.002", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+strategies+for+testing+software+product+lines%3A+A+systematic+literature+review&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref35"}, {"order": "36", "text": "Rupak Majumdar, Koushik Sen, \"Hybrid concolic testing\", <em>Proceedings of the InternationalConference on Software Engineering</em>, pp. 416-426, 2007.", "title": "Hybrid concolic testing", "context": [{"sec": "sec1", "text": " Our approach is similar in spirit to hybrid concolic execution [21], [36]; (implementation) we implemented S-SPLat, a variant of our previously-developed technique SPLat [29].", "part": "1"}, {"sec": "sec3", "text": " The intuition is that the use of heuristics can provide a better balance between cost and reliability and that balance is essential for practicality in this domain [10], [34], [36].", "part": "1"}, {"sec": "sec6a1d", "text": " Hybrid concolic execution [21], [36] is a variant of concolic execution that aims to explore the state space more broadly and deeply compared to a regular concolic execution, which conceptually can get stuck (e.g., as observed with saturation in coverage) in dense branches of the symbolic tree.", "part": "1"}], "links": {"documentLink": "/document/4222603", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=4222603", "abstract": "We present hybrid concolic testing, an algorithm that interleaves random testing with concolic execution to obtain both a deep and a wide exploration of program state space. Our algorithm generates test inputs automatically by interleaving random testing until saturation with bounded exhaustive symbolic exploration of program points. It thus combines the ability of random search to reach deep program states quickly together with the ability of concolic testing to explore states in a neighborhood...", "pdfSize": "153KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Hybrid+concolic+testing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref36"}, {"order": "37", "text": "Dusica Marijan, Arnaud Gotlieb, Sagar Sen, Aymeric Hervieu, \"Practical pairwise testing for software product lines\", <em>Proceedings of the Software Product Line Conference</em>, pp. 227-235, 2013.", "title": "Practical pairwise testing for software product lines", "context": [{"sec": "sec6a1b", "text": " [37] use the t-wise sampling algorithm to cover all t configuration option combinations.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2491627.2491646", "abstract": "One key challenge for software product lines is efficiently managing variability throughout their lifecycle. In this paper, we address the problem of variability in software product lines testing. We (1) identify a set of issues that must be addressed to make software product line testing work in practice and (2) provide a framework that combines a set of techniques to solve these issues. The framework integrates feature modelling, combinatorial interaction testing and constraint programming tec...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Practical+pairwise+testing+for+software+product+lines&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref37"}, {"order": "38", "text": "Fl\u00e1vio Medeiros, Christian K\u00e4stner, M\u00e1rcie Ribeiro, Rohit Gheyi, Sven Apel, \"A comparison of 10 sampling algorithms for configurable systems\", <em>Proceedings of the InternationalConference on Software Engineering</em>, pp. 643-654, 2016.", "title": "A comparison of 10 sampling algorithms for configurable systems", "context": [{"sec": "sec1", "text": "Combinatorial Interaction Testing (CIT) [51] has been popularized to balance probability of finding configuration errors (i.e., efficacy) and efficiency [17], [30], [31], [38], [42].", "part": "1"}, {"sec": "sec1", "text": "We analyzed S-SPLat with five basic heuristics that have demonstrated promising results in different studies [11], [38] and eleven combinations of these basic heuristics.", "part": "1"}, {"sec": "sec2b", "text": "Among the various sampling heuristics proposed in the literature related to testing configurable systems, we considered those that have been recently evaluated and are applicable in our context [11], [38].", "part": "1"}, {"sec": "sec5a2", "text": " To note that previous studies used similar metrics for similar reasons [26], [38].", "part": "1"}, {"sec": "sec5e", "text": " [38] showing the superior performance of this combination.", "part": "1"}, {"sec": "sec6a1b", "text": " [38] conducted an extensive comparative study of 10 sampling algorithms (5 variations of \\$t\\$-wise, statement-coverage, random, one-disabled, one-enabled, and most-enabled-disabled) regarding their fault-detection ability and size of sample sets in the Linux kernel, Apache, and other real C program families.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2884781.2884793", "abstract": "Almost every software system provides configuration options to tailor the system to the target platform and application scenario. Often, this configurability renders the analysis of every individual system configuration infeasible. To address this problem, researchers have proposed a diverse set of sampling algorithms. We present a comparative study of 10 state-of-the-art sampling algorithms regarding their fault-detection capability and size of sample sets. The former is important to improve so...", "pdfSize": "346KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+comparison+of+10+sampling+algorithms+for+configurable+systems&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref38"}, {"order": "39", "text": "Fl\u00e1vio Medeiros, M\u00e1rcio Ribeiro, Rohit Gheyi, \"Investigating preprocessor-based syntax errors\", <em>Proceedings of the Generative Programming: Concepts and Experiences</em>, pp. 75-84, 2013.", "title": "Investigating preprocessor-based syntax errors", "context": [{"sec": "sec1", "text": " Unfortunately, configuration-related errors are not rare [11], [19], [25], [39].", "part": "1"}, {"sec": "sec5b4", "text": " These results confirm previous observations that configuration-related errors are often manifested in configurations involving a small number of input options [11], [19], [31], [39].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2517208.2517221", "abstract": "The C preprocessor is commonly used to implement variability in program families. Despite the widespread usage, some studies indicate that the C preprocessor makes variability implementation difficult and error-prone. However, we still lack studies to investigate preprocessor-based syntax errors and quantify to what extent they occur in practice. In this paper, we define a technique based on a variability-aware parser to find syntax errors in releases and commits of program families. To investig...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Investigating+preprocessor-based+syntax+errors&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref39"}, {"order": "40", "text": "Jens Meinicke, Chu-Pan Wong, Christian K\u00e4stner, Thomas Th\u00fcm, Gunter Saake, \"On essential configuration complexity: Measuring interactions in highly-configurable systems\", <em>Proceedings of the Automated Software Engineering</em>, pp. 483-494, 2016.", "title": "On essential configuration complexity: Measuring interactions in highly-configurable systems", "context": [{"sec": "sec1", "text": " Recent empirical studies indicate that scalability depends on many factors including the subjects and tests used [40], [47], [49].", "part": "1"}, {"sec": "sec5a1a", "text": "We selected eight SPLs previously used in other studies [13], [26], [32], [40].", "part": "1"}, {"sec": "sec6a1d", "text": "Recent empirical study found evidence that practical configuration complexity is often much lower compared to theoretical configuration complexity [40].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2970276.2970322", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+essential+configuration+complexity%3A+Measuring+interactions+in+highly-configurable+systems&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref40"}, {"order": "41", "text": "Hung Viet Nguyen, Christian K\u00e4stner, Tien N. Nguyen, \"Exploring variability-aware execution for testing plugin-based web applications\", <em>Proceedings of the International Conference on Software Engineering</em>, pp. 907-918, 2014.", "title": "Exploring variability-aware execution for testing plugin-based web applications", "context": [{"sec": "sec1", "text": "More recently, sound testing techniques have been proposed [28], [29], [33], [41]; they assure that all configuration errors that can be captured with a given test will be captured.", "part": "1"}, {"sec": "sec6a1a", "text": " Multi-execution approaches, such as DeltaExecution [18], SharedExecution [28] and Varex [41], execute a given test simultaneously against sets of configurations; they leverage the similarities that exist across configurations to reduce the total number of paths explored in a test and the overall amount of computation.", "part": "1"}, {"sec": "sec6a1a", "text": " [41]).", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Exploring+variability-aware+execution+for+testing+plugin-based+web+applications&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref41"}, {"order": "42", "text": "Changhai Nie, Hareton Leung, \"A survey of combinatorial testing\", <em>ACM Computing Surveys</em>, vol. 43, no. 2, pp. 11:1-11:29, 2011.", "title": "A survey of combinatorial testing", "context": [{"sec": "sec1", "text": "Combinatorial Interaction Testing (CIT) [51] has been popularized to balance probability of finding configuration errors (i.e., efficacy) and efficiency [17], [30], [31], [38], [42].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/1883612.1883618", "abstract": "Combinatorial Testing (CT) can detect failures triggered by interactions of parameters in the Software Under Test (SUT) with a covering array test suite generated by some sampling mechanisms. It has been an active field of research in the last twenty years. This article aims to review previous work on CT, highlights the evolution of CT, and identifies important issues, methods, and applications of CT, with the goal of supporting and directing future practice and research in this area. First, we ...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+survey+of+combinatorial+testing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref42"}, {"order": "43", "text": "Thomas J. Ostrand, Marc J. Balcer, \"The category-partition method for specifying and generating functional tests\", <em>Communications of ACM</em>, vol. 31, no. 6, pp. 676-686, 1988.", "title": "The category-partition method for specifying and generating functional tests", "context": [{"sec": "sec4c", "text": " Instead, we applied the Ostrand and Barcer's category partitioning method [43], treating range types as boolean types.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/62959.62964", "abstract": "A method for creating functional test suites has been developed in which a test engineer analyzes the system specification, writes a series of formal test specifications, and then uses a generator tool to produce test descriptions from which test scripts are written. The advantages of this method are that the tester can easily modify the test specification when necessary, and can control the complexity and number of the tests by annotating the tests specification with constraints.", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=The+category-partition+method+for+specifying+and+generating+functional+tests&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref43"}, {"order": "44", "text": "Gilles Perrouin, Sagar Sen, Jacques Klein, Benoit Baudry, Yves le Traon, \"Automated and scalable t-wise test case generation strategies for software product lines\", <em>Proceedings of the International Conference on Software Testing Verification and Validation</em>, pp. 459-468, 2010.", "title": "Automated and scalable t-wise test case generation strategies for software product lines", "context": [{"sec": "sec6a1b", "text": " [44] and Marijan et al. [37] use the t-wise sampling algorithm to cover all t configuration option combinations.", "part": "1"}], "links": {"abstract": "Software Product Lines (SPL) are difficult to validate due to combinatorics induced by variability across their features. This leads to combinatorial explosion of the number of derivable products. Exhaustive testing in such a large space of products is infeasible. One possible option is to test SPLs by generating test cases that cover all possible T feature interactions (T-wise). T-wise dramatically reduces the number of test products while ensuring reasonable SPL coverage. However, automatic ge...", "pdfSize": "1417KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Automated+and+scalable+t-wise+test+case+generation+strategies+for+software+product+lines&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref44"}, {"order": "45", "text": "Koushik Sen, George Necula, Liang Gong, Wontae Choi, \"MultiSE: Multi-path symbolic execution using value summaries\", <em>Proceedings of the Foundations of Software Engineering</em>, pp. 842-853, 2015.", "title": "MultiSE: Multi-path symbolic execution using value summaries", "context": [{"sec": "sec6a1a", "text": " On the one hand, building (and maintaining) such interpreters is challenging, especially for statically-typed languages [18], [28], [45].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2786805.2786830", "abstract": "Dynamic symbolic execution (DSE) has been proposed to effectively generate test inputs for real-world programs. Unfortunately, DSE techniques do not scale well for large realistic programs, because often the number of feasible execution paths of a program increases exponentially with the increase in the length of an execution path. In this paper, we propose MultiSE, a new technique for merging states incrementally during symbolic execution, without using auxiliary variables. The key idea of Mult...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=MultiSE%3A+Multi-path+symbolic+execution+using+value+summaries&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref45"}, {"order": "46", "text": "Charles Song, Adam Porter, Jeffrey S. Foster, \"iTree: Efficiently discovering high-coverage configurations using interaction trees\", <em>Proceedings of the International Conference on Software Engineering</em>, pp. 903-913, 2012.", "title": "iTree: Efficiently discovering high-coverage configurations using interaction trees", "context": [{"sec": "sec6a1b", "text": " [46] propose interaction tree discovery algorithm (iTree) to support the testing of highly configurable systems. iTree selects a subset of configurations in which the execution of the system's test suite will achieve high coverage.", "part": "1"}], "links": {"documentLink": "/document/6227129", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6227129", "abstract": "Software configurability has many benefits, but it also makes programs much harder to test, as in the worst case the program must be tested under every possible configuration. One potential remedy to this problem is combinatorial interaction testing (CIT), in which typically the developer selects a strength t and then computes a covering array containing all t-way configuration option combinations. However, in a prior study we showed that several programs have important high-strength interaction...", "pdfSize": "491KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=iTree%3A+Efficiently+discovering+high-coverage+configurations+using+interaction+trees&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref46"}, {"order": "47", "text": "Sabrina Souto, Marcelo d'Amorim, <em>Time-Space Efficient Regression Testing for Configurable Systems</em>.", "title": "Time-Space Efficient Regression Testing for Configurable Systems", "context": [{"sec": "sec1", "text": " Recent empirical studies indicate that scalability depends on many factors including the subjects and tests used [40], [47], [49].", "part": "1"}, {"sec": "sec1", "text": " In this study, we used SPLat [29], [47], [49], a sound technique, previously developed by the authors, that monitors variable accesses in one execution and, based on that, decides which configurations should be executed next.", "part": "1"}, {"sec": "sec3", "text": " Unfortunately, we observed that, for a large system, such as GCC, with hundreds of configuration options, exploring all reachable configurations is impractical for several tests [47], [49].", "part": "1"}, {"sec": "sec6a1c", "text": " Despite the positive results reported by Kim et al. (caveat: evaluation involved large subjects but tests cover only a small fraction of the code), it is important to note that obtaining reachability information for these systems per test is challenging as: (i) the analysis needs to (re)run for each test, (ii) the analysis needs to run whenever the program changes, and (iii) often tests are designed to statically reach the entire codebase (e.g., system tests) \u2014 i.e., only the test input data can discriminate which parts of the code will be actually executed [47].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Time-Space+Efficient+Regression+Testing+for+Configurable+Systems&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref47"}, {"order": "48", "text": "Sabrina Souto, Marcelo d'Amorim, Rohit Gheyi, <em>S-SP Lat: Balancing soundness and efficiency for practical testing of configurable systems (Artifact)</em>,  [online]  Available: https://sabrinadfs.github.io/s-splat/.", "title": "S-SP Lat: Balancing soundness and efficiency for practical testing of configurable systems (Artifact)", "context": [{"sec": "sec1", "text": " The code, datasets, containers, and scripts are all accessible from our website [48].", "part": "1"}, {"sec": "sec5d", "text": " Our datasets and implementations are publicly available [48].", "part": "1"}, {"sec": "sec5e", "text": " Additional results can be found on our website [48].", "part": "1"}, {"sec": "sec7", "text": " Implementation and experimental infrastructure can be found on our website [48].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=S-SP+Lat%3A+Balancing+soundness+and+efficiency+for+practical+testing+of+configurable+systems+%28Artifact%29&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref48"}, {"order": "49", "text": "Sabrina Souto, Divya Gopinath, Marcelo d'Amorim, Darko Marinov, Sarfraz Khurshid, Don Batory, \"Faster bug detection for software product lines with incomplete feature models\", <em>Proceedings of the Software Product Line Conference</em>, pp. 151-160, 2015.", "title": "Faster bug detection for software product lines with incomplete feature models", "context": [{"sec": "sec1", "text": " Recent empirical studies indicate that scalability depends on many factors including the subjects and tests used [40], [47], [49].", "part": "1"}, {"sec": "sec1", "text": " In this study, we used SPLat [29], [47], [49], a sound technique, previously developed by the authors, that monitors variable accesses in one execution and, based on that, decides which configurations should be executed next.", "part": "1"}, {"sec": "sec1", "text": " The heuristic variants of S-SPLat were able to find all five crashes that we previously-documented [49] on GCC release 4.8.2 and uncovered two new crashes on release 6.1, one of which was reported to the GCC team and was already fixed.", "part": "1"}, {"sec": "sec3", "text": " Unfortunately, we observed that, for a large system, such as GCC, with hundreds of configuration options, exploring all reachable configurations is impractical for several tests [47], [49].", "part": "1"}, {"sec": "sec5b", "text": " We focused on crashes that the authors found in a previous study [49].", "part": "1"}, {"sec": "sec5b1a", "text": " We focused on that suite because previous study has shown a higher incidence of bugs found with it [49].", "part": "1"}, {"sec": "sec5b4", "text": "Next we evaluated the techniques on bugs found in a study, previously conducted by some of the authors of this paper, on release 4.8.2 of GCC [49].", "part": "1"}, {"sec": "sec5c", "text": " Considering the crash scenarios of GCC, we observed that all crashes found manifested in valid configurations, indicating that the use of validation is not beneficial. (We used GCC constraints documented in a previous study we conducted [49].) Considering the scenarios of failures of GCC, we also observed that the techniques performed consistently with and without feature constraints.", "part": "1"}, {"sec": "sec6a1a", "text": " Single-execution approaches, such as SPLat [29], [49], in contrast, execute a test once for each reachable configuration that they discover while building a decision tree from configuration variables accessed during execution.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2791060.2791093", "abstract": "A software product line (SPL) is a family of programs that are differentiated by features --- increments in functionality. Systematically testing an SPL is challenging because it requires running each test of a test suite against a combinatorial number of programs. Feature models capture dependencies among features and can (1) reduce the space of programs to test and (2) enable accurate categorization of failing tests as failures of programs or the tests themselves, not as failures due to illega...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Faster+bug+detection+for+software+product+lines+with+incomplete+feature+models&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref49"}, {"order": "50", "text": "Reinhard Tartler, Daniel Lohmann, Christian Dietrich, Christoph Egger, Julio Sincero, \"Configuration coverage in the analysis of large-scale system software\", <em>Proceedings of the Programming Languages and Operating Systems</em>, pp. 2:1-2:5, 2011.", "title": "Configuration coverage in the analysis of large-scale system software", "context": [{"sec": "sec6a1b", "text": " [50] propose the statement-coverage sampling algorithm and applied a per-file analysis to detect bugs in the Linux kernel.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2039239.2039242", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Configuration+coverage+in+the+analysis+of+large-scale+system+software&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref50"}, {"order": "51", "text": "<em>Lincoln University of Nebraska. Combinatorial interaction testing (CIT) portal</em>,  [online]  Available: http://cse.unl.edu/-citportal/.", "title": "Lincoln University of Nebraska. Combinatorial interaction testing (CIT) portal", "context": [{"sec": "sec1", "text": "Combinatorial Interaction Testing (CIT) [51] has been popularized to balance probability of finding configuration errors (i.e., efficacy) and efficiency [17], [30], [31], [38], [42].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Lincoln+University+of+Nebraska.+Combinatorial+interaction+testing+%28CIT%29+portal&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref51"}, {"order": "52", "text": "Alan W. Williams, Robert L. Probert, \"A practical strategy for testing pair-wise coverage of network interfaces\", <em>Proceedings of the InternationalSymposium on Software Reliability Engineering</em>, pp. 246-254, 1996.", "title": "A practical strategy for testing pair-wise coverage of network interfaces", "context": [{"sec": "sec1", "text": " For example, pairwise testing adequacy [52] is obtained when the sample set of selected configurations covers all possible pairs of input options.", "part": "1"}, {"sec": "sec1", "text": " Overall, considering our experimental setup, results suggest that it is preferable to combine some heuristics that demand a relatively low number of test requirements (e.g., one-enabled and one-disabled [11]) than using heuristics that solicit more test requirements (e.g., pairwise [52]).", "part": "1"}, {"sec": "sec2b", "text": " Finally, \\$t\\$-wise [52] samples all combinations of \\$t\\$ configuration options.", "part": "1"}], "links": {"abstract": "Distributed systems consist of a number of network elements that interact with each other. As the number of network elements and interchangeable components for each network element increases, the trade-off that the system tester faces is the thoroughness of test configuration coverage vs. limited resources of time and expense that are available. An approach to resolving this trade-off is to determine a set of test configurations that test each pair-wise combination of network components. This go...", "pdfSize": "743KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+practical+strategy+for+testing+pair-wise+coverage+of+network+interfaces&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref52"}], "pdfLink": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985700", "articleId": "7985700", "startPage": "632", "endPage": "642", "pubLink": "https://ieeexplore.ieee.org/xpl/conhome/7976701/proceeding", "issueLink": "https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7985634", "publisher": "IEEE", "confLoc": "Buenos Aires, Argentina", "chronDate": "20-28 May 2017", "metrics": {"citationCountPaper": 1, "citationCountPatent": 0, "totalDownloads": 178}}
{"title": "Stochastic Optimization of Program Obfuscation", "authors": [{"name": "Han Liu", "affiliation": "Sch. of Software, Tsinghua Univ., Beijing, China", "firstName": "Han", "lastName": "Liu", "id": "37085952777"}, {"name": "Chengnian Sun", "affiliation": "Univ. of California, Davis, Davis, CA, USA", "firstName": "Chengnian", "lastName": "Sun", "id": "37085881013"}, {"name": "Zhendong Su", "affiliation": "Univ. of California, Davis, Davis, CA, USA", "firstName": "Zhendong", "lastName": "Su", "id": "37086131381"}, {"name": "Yu Jiang", "affiliation": "Sch. of Software, Tsinghua Univ., Beijing, China", "firstName": "Yu", "lastName": "Jiang", "id": "37085432243"}, {"name": "Ming Gu", "affiliation": "Sch. of Software, Tsinghua Univ., Beijing, China", "firstName": "Ming", "lastName": "Gu", "id": "37085365607"}, {"name": "Jiaguang Sun", "affiliation": "Sch. of Software, Tsinghua Univ., Beijing, China", "firstName": "Jiaguang", "lastName": "Sun", "id": "37086130954"}], "abstract": "Program obfuscation is a common practice in software development to obscure source code or binary code, in order to prevent humans from understanding the purpose or logic of software. It protects intellectual property and deters malicious attacks. While tremendous efforts have been devoted to the development of various obfuscation techniques, we have relatively little knowledge on how to most effectively use them together. The biggest challenge lies in identifying the most effective combination of obfuscation techniques. This paper presents a unified framework to optimize program obfuscation. Given an input program P and a set T of obfuscation transformations, our technique can automatically identify a sequence seq = \u3008t\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sub>\n, t\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub>\n, ..., t\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">n</sub>\n\u3009 (\u2200i \u2208 [1, n]. t\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i</sub>\n \u2208 T), such that applying ti in order on P yields the optimal obfuscation performance. We model the process of searching for seq as a mathematical optimization problem. The key technical contributions of this paper are: (1) an obscurity language model to assess obfuscation effectiveness/optimality, and (2) a guided stochastic algorithm based on Markov chain Monte Carlo methods to search for the optimal solution seq. We have realized the framework in a tool Closure* for JavaScript, and evaluated it on 25 most starred JavaScript projects on GitHub (19K lines of code). Our machinery study shows that Closure* outperforms the well-known Google Closure Compiler by defending 26% of the attacks initiated by JSNice. Our human study also reveals that Closure* is practical and can reduce the human attack success rate by 30%.", "keywords": [{"type": "IEEE Keywords", "kwd": ["Optimization", "Mathematical model", "Reactive power", "Markov processes", "Google", "Lenses", "Software"]}, {"type": "INSPEC: Controlled Indexing", "kwd": ["Java", "Markov processes", "Monte Carlo methods", "software engineering"]}, {"type": "INSPEC: Non-Controlled Indexing", "kwd": ["stochastic optimization", "program obfuscation", "software development", "source code", "binary code", "mathematical optimization problem", "guided stochastic algorithm", "obscurity language model", "Markov chain Monte Carlo methods", "JavaScript"]}, {"type": "Author Keywords ", "kwd": ["program obfuscation", "obscurity language model", "markov chain monte carlo methods"]}], "publication": "2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)", "doi": "10.1109/ICSE.2017.28", "ref": [{"order": "1", "text": "C. Collberg, C. Thomborson, D. Low, \"Manufacturing cheap resilient and stealthy opaque constructs\", <em>Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</em>, pp. 184-196, 1998.", "title": "Manufacturing cheap, resilient, and stealthy opaque constructs", "context": [{"sec": "sec1", "text": "To defend against potential adversaries, decades of research has been devoted to developing various obfuscation techniques [1]\u2013[6].", "part": "1"}, {"sec": "sec2a3", "text": " Typical operations include inserting opaque predicates [1] whose value is hard to infer, flattening [11] and function inlining which can complicate the control flow and delay human understanding.", "part": "1"}, {"sec": "sec7a", "text": " For practical software use, Collberg proposed the opaque predicate to obfuscate the program by inserting boolean valued expressions whose values are known to obfuscators but difficult to analyze for automatic tools [1].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/268946.268962", "abstract": "It has become common to distribute software in forms that are isomorphic to the original source code. An important example is Java bytecode. Since such codes are easy to decompile, they increase the risk of malicious reverse engineering attacks.In this paper we describe the design of a Java code obfuscator, a tool which - through the application of code transformations - converts a Java program into an equivalent one that is more difficult to reverse engineer.We describe a number of transformati...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Manufacturing+cheap%2C+resilient%2C+and+stealthy+opaque+constructs&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref1"}, {"order": "2", "text": "M. Sharif, A. Lanzi, J. Giffin, W. Lee, \"Impeding malware analysis using conditional code obfuscation\", <em>NDSS</em>, 2008.", "title": "Impeding malware analysis using conditional code obfuscation", "context": [{"sec": "sec1", "text": "To defend against potential adversaries, decades of research has been devoted to developing various obfuscation techniques [1]\u2013[2][6].", "part": "1"}, {"sec": "sec7a", "text": " Sharif employed the conditional code obfuscation at compilation phase to transform input dependent branch conditions and encrypt the body [2].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Impeding+malware+analysis+using+conditional+code+obfuscation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref2"}, {"order": "3", "text": "M. Dalla Preda, I. Mastroeni, R. Giacobazzi, \"A formal framework for property-driven obfuscation strategies\" in Fundamentals of Computation Theory, Berlin Heidelberg:Springer, vol. 8070, pp. 133-144, 2013.", "title": "A formal framework for property-driven obfuscation strategies", "context": [{"sec": "sec1", "text": "To defend against potential adversaries, decades of research has been devoted to developing various obfuscation techniques [1]\u2013[3][6].", "part": "1"}, {"sec": "sec7a", "text": " On the other side, Preda investigated the concrete program semantics instead of abstract semantics to guide the obfuscation process [3].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+formal+framework+for+property-driven+obfuscation+strategies&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref3"}, {"order": "4", "text": "P. Ananth, D. Gupta, Y. Ishai, A. Sahai, \"Optimizing obfuscation: Avoiding barrington's theorem\", <em>Proceedings of the 2014 ACM SIGSAC Conference on Computerand Communications Security</em>, pp. 646-658, 2014.", "title": "Optimizing obfuscation: Avoiding barrington's theorem", "context": [{"sec": "sec1", "text": "To defend against potential adversaries, decades of research has been devoted to developing various obfuscation techniques [1]\u2013[4][6].", "part": "1"}, {"sec": "sec7a", "text": " Other works were advanced in pursuit of better efficiency [4], [35].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2660267.2660342", "abstract": "In this work, we seek to optimize the efficiency of secure general-purpose obfuscation schemes. We focus on the problem of optimizing the obfuscation of Boolean formulas and branching programs -- this corresponds to optimizing the &#34;core obfuscator&#34; from the work of Garg, Gentry, Halevi, Raykova, Sahai, and Waters (FOCS 2013), and all subsequent works constructing general-purpose obfuscators. This core obfuscator builds upon approximate multilinear maps, where efficiency in proposed instantiation...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Optimizing+obfuscation%3A+Avoiding+barrington%27s+theorem&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref4"}, {"order": "5", "text": "R. Giacobazzi, N.D. Jones, I. Mastroeni, \"Obfuscation by partial evaluation of distorted interpreters\", <em>Proceedings of the ACM SIGPLAN 2012 Workshop on Partial Evaluation and Program Manipulation</em>, pp. 63-72, 2012.", "title": "Obfuscation by partial evaluation of distorted interpreters", "context": [{"sec": "sec1", "text": "To defend against potential adversaries, decades of research has been devoted to developing various obfuscation techniques [1]\u2013[5][6].", "part": "1"}, {"sec": "sec7a", "text": " Regarding abstract interpretation [38], Giacobazzi leveraged interpreter distortion to generate obfuscated code [5] with the notion of incompleteness [39].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2103746.2103761", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Obfuscation+by+partial+evaluation+of+distorted+interpreters&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref5"}, {"order": "6", "text": "C. Linn, S. Debray, \"Obfuscation of executable code to improve resistance to static disassembly\", <em>Proceedings of the 10th ACM Conference on Computerand Communications Security</em>, pp. 290-299, 2003.", "title": "Obfuscation of executable code to improve resistance to static disassembly", "context": [{"sec": "sec1", "text": "To defend against potential adversaries, decades of research has been devoted to developing various obfuscation techniques [1]\u2013[6].", "part": "1"}, {"sec": "sec7a", "text": " Differently, Linn presented a complement to thwart disassembling process which translates machine code to assembly code [6].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/948148.948149", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Obfuscation+of+executable+code+to+improve+resistance+to+static+disassembly&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref6"}, {"order": "7", "text": "V. Raychev, M. Vechev, A. Krause, \"Predicting program properties from \u201cbig code\u201d\", <em>Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</em>, pp. 111-124, 2015.", "title": "Predicting program properties from \u201cbig code\u201d", "context": [{"sec": "sec1", "text": " These adversaries [7], [8] leverage coding features mined from a large corpus of source code to recover useful information (e.g., identifier names, types) from obfuscated programs.", "part": "1"}, {"sec": "sec1a3", "text": " The evaluation on real-world popular open-source projects (over 19K lines of code) demonstrates the ability of Closure* at combating the state-of-the-art deobfuscator JSNice [7].", "part": "1"}, {"sec": "sec2b", "text": "We take JSNice [7] as a powerful instance.", "part": "1"}, {"sec": "sec2b", "text": " For name obfuscation as in \u00a7II-A, JSNice can correctly predict 63.4% of the obfuscated names [7], making the obfuscation greatly compromised.", "part": "1"}, {"sec": "sec2b", "text": " Even for complex large programs, JSNice can recover sensitive code elements within an acceptable time bound [7].", "part": "1"}, {"sec": "sec4b1", "text": " Using JSNice [7] as an automatic adversary to attack the two code snippets also confirms this.", "part": "1"}, {"sec": "sec6b", "text": " As for the adversary to Closure*, we use the UnuglifyJS front-end [19] and the Nice2Predict underlying machine learning engine [20], which are both from JSNice [7].", "part": "1"}, {"sec": "sec6b1", "text": " While featured as an optimizer for JavaScript [9], such tools are characterized as a form of obfuscators by JSNice [7] (They used UglifyJS, which is similar to Closure).", "part": "1"}, {"sec": "sec7b", "text": " Towards the application of suggesting names, Allamanis [41] and Raychev [7] addressed the naming for variables while Allamanis handled methods and classes as well [8].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2676726.2677009", "abstract": "We present a new approach for predicting program properties from massive codebases (aka &#34;Big Code&#34;). Our approach first learns a probabilistic model from existing data and then uses this model to predict properties of new, unseen programs. The key idea of our work is to transform the input program into a representation which allows us to phrase the problem of inferring program properties as structured prediction in machine learning. This formulation enables us to leverage powerful probabilistic ...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Predicting+program+properties+from+%E2%80%9Cbig+code%E2%80%9D&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref7"}, {"order": "8", "text": "M. Allamanis, E.T. Barr, C. Bird, C. Sutton, \"Suggesting accurate method and class names\", <em>Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering</em>, pp. 38-49, 2015.", "title": "Suggesting accurate method and class names", "context": [{"sec": "sec1", "text": " These adversaries [7], [8] leverage coding features mined from a large corpus of source code to recover useful information (e.g., identifier names, types) from obfuscated programs.", "part": "1"}, {"sec": "sec7b", "text": " Towards the application of suggesting names, Allamanis [41] and Raychev [7] addressed the naming for variables while Allamanis handled methods and classes as well [8].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2786805.2786849", "abstract": "Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilisti...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Suggesting+accurate+method+and+class+names&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref8"}, {"order": "9", "text": "<em>The Google Closure Compiler</em>,  [online]  Available: https://developers.google.com/closure/compiler/.", "title": "The Google Closure Compiler", "context": [{"sec": "sec1", "text": " The state-of-the-art obfuscators, such as Google Closure Compiler [9], specify a fixed order of obfuscation transformations for all programs.", "part": "1"}, {"sec": "sec6b1", "text": " While featured as an optimizer for JavaScript [9], such tools are characterized as a form of obfuscators by JSNice [7] (They used UglifyJS, which is similar to Closure).", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=The+Google+Closure+Compiler&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref9"}, {"order": "10", "text": "C. Andrieu, N. de Freitas, A. Doucet, M. Jordan, \"An introduction to mcmc for machine learning\", <em>Machine Learning</em>, vol. 50, no. 1\u20132, pp. 5-43, 2003.", "title": "An introduction to mcmc for machine learning", "context": [{"sec": "sec1a2", "text": "Second, we realize the optimization process by using Markov chain Monte Carlo (MCMC) [10] methods to search for the optimal configuration of obfuscation transformations.", "part": "1"}, {"sec": "sec5a", "text": "In this paper, we employ MCMC sampling [10] to find seq*.", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1023/A:1020281327116", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=An+introduction+to+mcmc+for+machine+learning&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref10"}, {"order": "11", "text": "T. L\u00e1szl\u00f3, \u00c1. Kiss, \"Obfuscating c++ programs via control flow flattening\", <em>Annales Universitatis Scientarum Budapestinensis de Rolando E\u00f6tv\u00f6s Nominatae Sectio Computatorica</em>, vol. 30, pp. 3-19, 2009.", "title": "Obfuscating c++ programs via control flow flattening", "context": [{"sec": "sec2a3", "text": " Typical operations include inserting opaque predicates [1] whose value is hard to infer, flattening [11] and function inlining which can complicate the control flow and delay human understanding.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Obfuscating+c%2B%2B+programs+via+control+flow+flattening&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref11"}, {"order": "12", "text": "A. Hindle, E.T. Barr, Z. Su, M. Gabel, P. Devanbu, \"On the naturalness of software\", <em>Proceedings of the 34th International Conference on Software Engineering</em>, pp. 837-847, 2012.", "title": "On the naturalness of software", "context": [{"sec": "sec2c", "text": " In the context of programming languages, researchers have investigated such probabilistic nature (called naturalness) of programs [12] and highlighted its promising potential in handling traditional software engineering tasks [13]\u2013[15], e.g., for code completion, given code snippet for{, the LM can predict for{int i=0; i< is the most possible code to follow.", "part": "1"}, {"sec": "sec4a", "text": "As stated in [12], building a general language model for source code aims at capturing the statistical regularities of code.", "part": "1"}, {"sec": "sec4b", "text": "Different from a traditional language model for software engineering tasks at unobfuscated source code level (e.g., code completion) [12], [14], [15], our OLM aims to capture the remaining regularities of software after obfuscation.", "part": "1"}, {"sec": "sec7b", "text": " Based on the classical n-gram model, Hindle exploited the naturalness of software, which proved code to be predictable and led to a programming suggestion engine [12].", "part": "1"}], "links": {"documentLink": "/document/6227135", "pdfLink": "/stamp/stamp.jsp?tp=&arnumber=6227135", "abstract": "Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal s...", "pdfSize": "383KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+naturalness+of+software&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref12"}, {"order": "13", "text": "V. Raychev, M. Vechev, E. Yahav, \"Code completion with statistical language models\", <em>Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation</em>, pp. 419-428, 2014.", "title": "Code completion with statistical language models", "context": [{"sec": "sec2c", "text": " In the context of programming languages, researchers have investigated such probabilistic nature (called naturalness) of programs [12] and highlighted its promising potential in handling traditional software engineering tasks [13]\u2013[15], e.g., for code completion, given code snippet for{, the LM can predict for{int i=0; i< is the most possible code to follow.", "part": "1"}, {"sec": "sec7b", "text": " In terms of method sequence, Raychev built the language models on call sequences [13].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Code+completion+with+statistical+language+models&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref13"}, {"order": "14", "text": "T.T. Nguyen, A.T. Nguyen, H.A. Nguyen, T.N. Nguyen, \"A statistical semantic language model for source code\", <em>Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering</em>, pp. 532-542, 2013.", "title": "A statistical semantic language model for source code", "context": [{"sec": "sec2c", "text": " In the context of programming languages, researchers have investigated such probabilistic nature (called naturalness) of programs [12] and highlighted its promising potential in handling traditional software engineering tasks [13]\u2013[14][15], e.g., for code completion, given code snippet for{, the LM can predict for{int i=0; i< is the most possible code to follow.", "part": "1"}, {"sec": "sec4a", "text": "Recent techniques [14], [15] can build better language models to capture the regularities of programs, by either associating the lexemes with semantic information or taking the localness of lexemes into account during the model training phase.", "part": "1"}, {"sec": "sec4b", "text": "Different from a traditional language model for software engineering tasks at unobfuscated source code level (e.g., code completion) [12], [14], [15], our OLM aims to capture the remaining regularities of software after obfuscation.", "part": "1"}, {"sec": "sec7b", "text": " Nguyen extended the model with sememes to involve semantic information other than lexemes [14].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2491411.2491458", "abstract": "Recent research has successfully applied the statistical n-gram language model to show that source code exhibits a good level of repetition. The n-gram model is shown to have good predictability in supporting code suggestion and completion. However, the state-of-the-art n-gram approach to capture source code regularities/patterns is based only on the lexical information in a local context of the code units. To improve predictability, we introduce SLAMC, a novel statistical semantic language mode...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+statistical+semantic+language+model+for+source+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref14"}, {"order": "15", "text": "Z. Tu, Z. Su, P. Devanbu, \"On the localness of software\", <em>Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering</em>, pp. 269-280, 2014.", "title": "On the localness of software", "context": [{"sec": "sec2c", "text": " In the context of programming languages, researchers have investigated such probabilistic nature (called naturalness) of programs [12] and highlighted its promising potential in handling traditional software engineering tasks [13]\u2013[15], e.g., for code completion, given code snippet for{, the LM can predict for{int i=0; i< is the most possible code to follow.", "part": "1"}, {"sec": "sec4a", "text": "Recent techniques [14], [15] can build better language models to capture the regularities of programs, by either associating the lexemes with semantic information or taking the localness of lexemes into account during the model training phase.", "part": "1"}, {"sec": "sec4b", "text": "Different from a traditional language model for software engineering tasks at unobfuscated source code level (e.g., code completion) [12], [14], [15], our OLM aims to capture the remaining regularities of software after obfuscation.", "part": "1"}, {"sec": "sec7b", "text": " Moreover, the localness is further enriched by Tu via proposing a cache language model to absorb local constructs for predicting programs [15].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2635868.2635875", "abstract": "The n-gram language model, which has its roots in statistical natural language processing, has been shown to successfully capture the repetitive and predictable regularities (\u201cnaturalness&#34;) of source code, and help with tasks such as code suggestion, porting, and designing assistive coding devices. However, we show in this paper that this natural-language-based model fails to exploit a special property of source code: localness. We find that human-written programs are localized: they have useful...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+localness+of+software&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref15"}, {"order": "16", "text": "C.D. Manning, H. Sch\u00fctze, Foundations of statistical natural language processing, MIT Press, vol. 999, 1999.", "title": "Foundations of statistical natural language processing", "context": [{"sec": "sec2c", "text": "Given a program \\$s=t_{1}t_{2}\\cdots t_{n}\\$, to better interpret its naturalness based on an LM \\$\\mathcal{M}\\$, we use the measurement perplexity or its log-transformed version cross-entropy [16], defined as \\$H_{\\mathcal{M}}(s)=-\\frac{1}{n}\\log p_{\\mathcal{M}}(t_{1}\\cdots t_{n})\\$.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Foundations+of+statistical+natural+language+processing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref16"}, {"order": "17", "text": "E. Schkufza, R. Sharma, A. Aiken, \"Stochastic superoptimization\", <em>Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems</em>, pp. 305-316, 2013.", "title": "Stochastic superoptimization", "context": [{"sec": "sec5a", "text": "As described in [17], \\$\\sigma\\$ is a constant and \\$Z\\$ is a partition function that normalizes the target distribution.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2451116.2451150", "abstract": "We formulate the loop-free binary superoptimization task as a stochastic search problem. The competing constraints of transformation correctness and performance improvement are encoded as terms in a cost function, and a Markov Chain Monte Carlo sampler is used to rapidly explore the space of all possible programs to find one that is an optimization of a given target program. Although our method sacrifices completeness, the scope of programs we are able to consider, and the resulting quality of t...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Stochastic+superoptimization&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref17"}, {"order": "18", "text": "<em>KenLM</em>,  [online]  Available: https://github.com/kpu/kenlm.", "title": "KenLM", "context": [{"sec": "sec6b", "text": " In evaluation, the obscurity LM is configured to be 5-gram using KenLM [18].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=KenLM&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref18"}, {"order": "19", "text": "<em>UnuglifyJS</em>,  [online]  Available: https://github.com/eth-srl/UnuglifyJS.", "title": "UnuglifyJS", "context": [{"sec": "sec6b", "text": " As for the adversary to Closure*, we use the UnuglifyJS front-end [19] and the Nice2Predict underlying machine learning engine [20], which are both from JSNice [7].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=UnuglifyJS&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref19"}, {"order": "20", "text": "<em>Nice2Predict</em>,  [online]  Available: https://github.com/eth-srl/Nice2Predict.", "title": "Nice2Predict", "context": [{"sec": "sec6b", "text": " As for the adversary to Closure*, we use the UnuglifyJS front-end [19] and the Nice2Predict underlying machine learning engine [20], which are both from JSNice [7].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Nice2Predict&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref20"}, {"order": "21", "text": "<em>angular.js</em>,  [online]  Available: https://github.com/angular/angular.", "title": "angular.js", "context": [{"sec": "sec6d", "text": " We also listed results for top three popular projects: angular [21], meteor [22] and react [23], which have 20,000 GitHub stars on average.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=angular.js&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref21"}, {"order": "22", "text": "<em>meteor</em>,  [online]  Available: https://github.com/meteor/meteor.", "title": "meteor", "context": [{"sec": "sec6d", "text": " We also listed results for top three popular projects: angular [21], meteor [22] and react [23], which have 20,000 GitHub stars on average.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=meteor&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref22"}, {"order": "23", "text": "<em>react</em>,  [online]  Available: https://github.com/facebook/react.", "title": "react", "context": [{"sec": "sec6d", "text": " We also listed results for top three popular projects: angular [21], meteor [22] and react [23], which have 20,000 GitHub stars on average.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=react&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref23"}, {"order": "24", "text": "S. Siegel, N.J.J. Castellan, Nonparametric statistics for the behavioral sciences, New York, St. Louis:McGraw-Hill, 1988.", "title": "Nonparametric statistics for the behavioral sciences", "context": [{"sec": "sec6d", "text": " We also conduct the Wilcoxon Signed-Rank Test [24] over obfuscation results from Closure and Closure* to validate the statistical significance.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Nonparametric+statistics+for+the+behavioral+sciences&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref24"}, {"order": "25", "text": "R. Lowry, <em>Concepts and applications of inferential statistics</em>,  [online]  Available: http://vassarstats.net/textbook/ch12a.html.", "title": "Concepts and applications of inferential statistics", "context": [{"sec": "sec6d", "text": " With the 1.783 \\$z\\$-score which does not exceed the critical value 1.960 according to [25], the optimization is statistically significant.", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Concepts+and+applications+of+inferential+statistics&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref25"}, {"order": "26", "text": "C. Collberg, C. Thomborson, D. Low, \"A taxonomy of obfuscating transformations\", <em>Technical report 148</em>, 1997.", "title": "A taxonomy of obfuscating transformations", "context": [{"sec": "sec7a", "text": "Program obfuscation has been exensively studied to make reverse engineering or human understanding harder [26].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+taxonomy+of+obfuscating+transformations&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref26"}, {"order": "27", "text": "B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan, K. Yang, J. Kilian, \"On the (im)possibility of obfuscating programs\", <em>CRYPTO 2001</em>, vol. 2139, pp. 1-18, 2001.", "title": "On the (im)possibility of obfuscating programs", "context": [{"sec": "sec7a", "text": " Theoretically, it is claimed that no \u201cperfect\u201d obfuscation exists [27], [28].", "part": "1"}, {"sec": "sec7a", "text": " Despite of the impossibility, Barak suggested indistinguishability obfuscation [27], [29].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/3-540-44647-8_1", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+%28im%29possibility+of+obfuscating+programs&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref27"}, {"order": "28", "text": "S. Goldwasser, Y. Kalai, \"On the impossibility of obfuscation with auxiliary input\", <em>Foundations of Computer Science 2005. FOCS 2005. 46th Annual IEEE Symposium on</em>, pp. 553-562, Oct 2005.", "title": "On the impossibility of obfuscation with auxiliary input", "context": [{"sec": "sec7a", "text": " Theoretically, it is claimed that no \u201cperfect\u201d obfuscation exists [27], [28].", "part": "1"}], "links": {"abstract": "Barak et al. formalized the notion of obfuscation, and showed that there exist (contrived) classes of functions that cannot be obfuscated. In contrast, Canetti and Wee showed how to obfuscate point functions, under various complexity assumptions. Thus, it would seem possible that most programs of interest can be obfuscated even though in principle general purpose obfuscators do not exist. We show that this is unlikely to be the case. In particular; we consider the notion of obfuscation w.r.t. au...", "pdfSize": "348KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+impossibility+of+obfuscation+with+auxiliary+input&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref28"}, {"order": "29", "text": "B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan, K. Yang, \"On the (im) possibility of obfuscating programs\", <em>Journal of the ACM (JACM)</em>, vol. 59, no. 2, pp. 6, 2012.", "title": "On the (im) possibility of obfuscating programs", "context": [{"sec": "sec7a", "text": " Despite of the impossibility, Barak suggested indistinguishability obfuscation [27], [29].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2160158.2160159", "abstract": "Informally, an obfuscator O is an (efficient, probabilistic) \u201ccompiler\u201d that takes as input a program (or circuit) P and produces a new program O(P) that has the same functionality as P yet is \u201cunintelligible\u201d in some sense. Obfuscators, if they exist, would have a wide variety of cryptographic and complexity-theoretic applications, ranging from software protection to homomorphic encryption to complexity-theoretic analogues of Rice&#39;s theorem. Most of these applications are based on an interpreta...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+the+%28im%29+possibility+of+obfuscating+programs&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref29"}, {"order": "30", "text": "S. Garg, C. Gentry, S. Halevi, M. Raykova, A. Sahai, B. Waters, \"Candidate indistinguishability obfuscation and functional encryption for all circuits\", <em>Foundations of Computer Science(FOCS) 2013 IEEE 54th Annual Symposium on</em>, pp. 40-49, 2013.", "title": "Candidate indistinguishability obfuscation and functional encryption for all circuits", "context": [{"sec": "sec7a", "text": " Garg and Brakerski further presented obfuscators for polynomial-size circuits [30], [31].", "part": "1"}], "links": {"abstract": "In this work, we study indistinguishability obfuscation and functional encryption for general circuits: Indistinguishability obfuscation requires that given any two equivalent circuits C0 and C1 of similar size, the obfuscations of C0 and C1 should be computationally indistinguishable. In functional encryption, cipher texts encrypt inputs x and keys are issued for circuits C. Using the key SKC to decrypt a cipher text CTx = Enc(x), yields the value C(x) but does not reveal anything else about x....", "pdfSize": "251KB", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Candidate+indistinguishability+obfuscation+and+functional+encryption+for+all+circuits&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref30"}, {"order": "31", "text": "Z. Brakerski, G.N. Rothblum, \"Virtual black-box obfuscation for all circuits via generic graded encoding\", <em>Theory of Cryptography</em>, pp. 1-25, 2014.", "title": "Virtual black-box obfuscation for all circuits via generic graded encoding", "context": [{"sec": "sec7a", "text": " Garg and Brakerski further presented obfuscators for polynomial-size circuits [30], [31].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Virtual+black-box+obfuscation+for+all+circuits+via+generic+graded+encoding&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref31"}, {"order": "32", "text": "B. Barak, S. Garg, Y.T. Kalai, O. Paneth, A. Sahai, \"Protecting obfuscation against algebraic attacks\", <em>Advances in Cryptology-EUROCRYPT 2014</em>, pp. 221-238, 2014.", "title": "Protecting obfuscation against algebraic attacks", "context": [{"sec": "sec7a", "text": " Barak described a simplified variant to achieve protection against algebra attacks [32].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Protecting+obfuscation+against+algebraic+attacks&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref32"}, {"order": "33", "text": "A. Sahai, B. Waters, \"How to use indistinguishability obfuscation: deniable encryption and more\", <em>Proceedings of the 46th Annual ACM Symposium on Theory of Computing</em>, pp. 475-484, 2014.", "title": "How to use indistinguishability obfuscation: deniable encryption, and more", "context": [{"sec": "sec7a", "text": " Sahai proposed punctured programs for cryptographic problems [33].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2591796.2591825", "abstract": "We introduce a new technique, that we call punctured programs, to apply indistinguishability obfuscation towards cryptographic problems. We use this technique to carry out a systematic study of the applicability of indistinguishability obfuscation to a variety of cryptographic goals. Along the way, we resolve the 16-year-old open question of Deniable Encryption, posed by Canetti, Dwork, Naor, and Ostrovsky in 1997: In deniable encryption, a sender who is forced to reveal to an adversary both her...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=How+to+use+indistinguishability+obfuscation%3A+deniable+encryption%2C+and+more&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref33"}, {"order": "34", "text": "S. Goldwasser, G.N. Rothblum, \"On best-possible obfuscation\", <em>Theory of Cryptography</em>, pp. 194-213, 2007.", "title": "On best-possible obfuscation", "context": [{"sec": "sec7a", "text": " Goldwasser proposed to identify the best possible obfuscation which leaks as little information as other programs with the same functionality [34].", "part": "1"}], "links": {"crossRefLink": "https://doi.org/10.1007/978-3-540-70936-7_11", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=On+best-possible+obfuscation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref34"}, {"order": "35", "text": "J. Zimmerman, \"How to obfuscate programs directly\", <em>Advances in Cryptology-EUROCRYPT 2015</em>, pp. 439-467, 2015.", "title": "How to obfuscate programs directly", "context": [{"sec": "sec7a", "text": " Other works were advanced in pursuit of better efficiency [4], [35].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=How+to+obfuscate+programs+directly&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref35"}, {"order": "36", "text": "W. Mark, \"Program slicing\", <em>Proceedings of the 5th International Conference on Software Engineering</em>, pp. 439-449, 1981.", "title": "Program slicing", "context": [{"sec": "sec7a", "text": " Regarding program slicing [36] as the adversary, Drape transformed code so that the orphaned slices \u2014 code left after the slicing \u2014 are minimized [37].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Program+slicing&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref36"}, {"order": "37", "text": "D.S., M.A., T.C., \"Slicing aided design of obfuscating transforms\", <em>Computer and Information Science 2007. ICIS 2007. 6th IEEE/ACIS International Conference on</em>, pp. 1019-1024, 2007.", "title": "Slicing aided design of obfuscating transforms", "context": [{"sec": "sec7a", "text": " Regarding program slicing [36] as the adversary, Drape transformed code so that the orphaned slices \u2014 code left after the slicing \u2014 are minimized [37].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Slicing+aided+design+of+obfuscating+transforms&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref37"}, {"order": "38", "text": "P. Cousot, R. Cousot, \"Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints\", <em>Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages</em>, pp. 238-252, 1977.", "title": "Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints", "context": [{"sec": "sec7a", "text": " Regarding abstract interpretation [38], Giacobazzi leveraged interpreter distortion to generate obfuscated code [5] with the notion of incompleteness [39].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/512950.512973", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Abstract+interpretation%3A+A+unified+lattice+model+for+static+analysis+of+programs+by+construction+or+approximation+of+fixpoints&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref38"}, {"order": "39", "text": "R. Giacobazzi, I. Mastroeni, \"Making abstract interpretation incomplete: Modeling the potency of obfuscation\" in Static Analysis, Berlin Heidelberg:Springer, vol. 7460, pp. 129-145, 2012.", "title": "Making abstract interpretation incomplete: Modeling the potency of obfuscation", "context": [{"sec": "sec7a", "text": " Regarding abstract interpretation [38], Giacobazzi leveraged interpreter distortion to generate obfuscated code [5] with the notion of incompleteness [39].", "part": "1"}], "googleScholarLink": "https://scholar.google.com/scholar?as_q=Making+abstract+interpretation+incomplete%3A+Modeling+the+potency+of+obfuscation&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref39"}, {"order": "40", "text": "M. Gabel, Z. Su, \"A study of the uniqueness of source code\", <em>Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering</em>, pp. 147-156, 2010.", "title": "A study of the uniqueness of source code", "context": [{"sec": "sec7b", "text": "Due to the fact that software is repetitive and not unique [40], language models can be built for source code to capture regularities.", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/1882291.1882315", "abstract": "This paper presents the results of the first study of the uniqueness of source code. We define the uniqueness of a unit of source code with respect to the entire body of written software, which we approximate with a corpus of 420 million lines of source code. Our high-level methodology consists of examining a collection of 6,000 software projects and measuring the degree to which each project can be `assembled&#39; solely from portions of this corpus, thus providing a precise measure of `uniqueness&#39;...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=A+study+of+the+uniqueness+of+source+code&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref40"}, {"order": "41", "text": "M. Allamanis, E.T. Barr, C. Bird, C. Sutton, \"Learning natural coding conventions\", <em>Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering</em>, pp. 281-293, 2014.", "title": "Learning natural coding conventions", "context": [{"sec": "sec7b", "text": " Towards the application of suggesting names, Allamanis [41] and Raychev [7] addressed the naming for variables while Allamanis handled methods and classes as well [8].", "part": "1"}], "links": {"acmLink": "https://doi.org/10.1145/2635868.2635883", "abstract": "Every programmer has a characteristic style, ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style, fostering readability and hence maintainability. When collaborating, programmers strive to obey a project\u2019s coding conventions. However, one third of reviews of changes contain feedback about coding conventions, indicating that programmers do not always follow them and that project memb...", "openUrlImgLoc": "/assets/img/btn.find-in-library.png"}, "googleScholarLink": "https://scholar.google.com/scholar?as_q=Learning+natural+coding+conventions&as_occt=title&hl=en&as_sdt=0%2C31", "refType": "biblio", "id": "ref41"}], "pdfLink": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985664", "articleId": "7985664", "startPage": "221", "endPage": "231", "pubLink": "https://ieeexplore.ieee.org/xpl/conhome/7976701/proceeding", "issueLink": "https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7985634", "publisher": "IEEE", "confLoc": "Buenos Aires, Argentina", "chronDate": "20-28 May 2017", "metrics": {"citationCountPaper": 3, "citationCountPatent": 0, "totalDownloads": 363}}
