"Document Title","Authors","Author Affiliations","Publication Title","Date Added To Xplore","Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBNs","DOI","Funding Information","PDF Link","Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms","Article Citation Count","Reference Count","License","Online Date","Issue Date","Meeting Date","Publisher","Document Identifier"
"Keynotes","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","36","38","Provides an abstract for each of the keynote presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","","","10.1109/ASE.2019.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952191","","","","","","","","","","","","IEEE","IEEE Conferences"
"Big problems in industry (panel)","J. Penix","Google, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","3","3","Software Engineering in practice deals with scale in a variety of dimensions. We build large scale systems operating on vast amount of data. We have millions of customers with billions of queries and transactions. We have distributed teams making thousands of changes, running millions of tests and releasing multiple times per day. These dimensions of scale interact to provide challenges for software development tools and processes. The panelists will describe the challenging aspects of scale in their specific problem domains and discuss which software engineering methods work and which leave room for improvement.","","","10.1109/ASE.2013.6693060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693060","","","","","","1","","","","","","IEEE","IEEE Conferences"
"Toward Practical Automatic Program Repair","A. Ghanbari","University of Texas at Dallas","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1262","1264","Automated program repair (APR) reduces the burden of debugging by directly suggesting likely fixes for the bugs. We believe scalability, applicability, and accurate patch validation are among the main challenges for building practical APR techniques that the researchers in this area are dealing with. In this paper, we describe the steps that we are taking toward addressing these challenges.","","","10.1109/ASE.2019.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952355","Program Repair;JVM Bytecode;Mutation Testing","","","","","","54","","","","","IEEE","IEEE Conferences"
"TsmartGP: A Tool for Finding Memory Defects with Pointer Analysis","Y. Wang; G. Chen; M. Zhou; M. Gu; J. Sun","Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","""","1170","1173","Precise pointer analysis is desired since it is a core technique to find memory defects. There are several dimensions of pointer analysis precision, flow sensitivity, context sensitivity, field sensitivity and path sensitivity. For static analysis tools utilizing pointer analysis, considering all dimensions is difficult because the trade-off between precision and efficiency should be balanced. This paper presents TsmartGP, a static analysis tool for finding memory defects in C programs with a precise and efficient pointer analysis. The pointer analysis algorithm is flow, context, field, and quasi path sensitive. Control flow automatons are the key structures for our analysis to be flow sensitive. Function summaries are applied to get context information and elements of aggregate structures are handled to improve precision. Path conditions are used to filter unreachable paths. For efficiency, a multi-entry mechanism is proposed. Utilizing the pointer analysis algorithm, we implement a checker in TsmartGP to find uninitialized pointer errors in 13 real-world applications. Cppcheck and Clang Static Analyzer are chosen for comparison. The experimental results show that TsmartGP can find more errors while its accuracy is also higher than Cppcheck and Clang Static Analyzer.","","","10.1109/ASE.2019.00129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952426","pointer analysis;uninitialized pointer;sensitivity;multi-entry","","","","","","12","","","","","IEEE","IEEE Conferences"
"Retrieve and Refine: Exemplar-Based Neural Comment Generation","B. Wei","Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1250","1252","Code comment generation is a crucial task in the field of automatic software development. Most previous neural comment generation systems used an encoder-decoder neural network and encoded only information from source code as input. Software reuse is common in software development. However, this feature has not been introduced to existing systems. Inspired by the traditional IR-based approaches, we propose to use the existing comments of similar source code as exemplars to guide the comment generation process. Based on an open source search engine, we first retrieve a similar code and treat its comment as an exemplar. Then we applied a seq2seq neural network to conduct an exemplar-based comment generation. We evaluate our approach on a large-scale Java corpus, and experimental results demonstrate that our model significantly outperforms the state-of-the-art methods.","","","10.1109/ASE.2019.00152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952536","comment generation;program comprehension;deep learning","","","","","","21","","","","","IEEE","IEEE Conferences"
"Humanoid: A Deep Learning-Based Approach to Automated Black-box Android App Testing","Y. Li; Z. Yang; Y. Guo; X. Chen","Peking University; Peking University; Peking University; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1070","1073","Automated input generators must constantly choose which UI element to interact with and how to interact with it, in order to achieve high coverage with a limited time budget. Currently, most black-box input generators adopt pseudo-random or brute-force searching strategies, which may take very long to find the correct combination of inputs that can drive the app into new and important states. We propose Humanoid, an automated black-box Android app testing tool based on deep learning. The key technique behind Humanoid is a deep neural network model that can learn how human users choose actions based on an app's GUI from human interaction traces. The learned model can then be used to guide test input generation to achieve higher coverage. Experiments on both open-source apps and market apps demonstrate that Humanoid is able to reach higher coverage, and faster as well, than the state-of-the-art test input generators. Humanoid is open-sourced at https://github.com/yzygitzh/Humanoid and a demo video can be found at https://youtu.be/PDRxDrkyORs.","","","10.1109/ASE.2019.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952324","software testing;automated test input generation;graphical user interface;deep learning;mobile application;Android","","","","","","14","","","","","IEEE","IEEE Conferences"
"A Machine Learning Based Approach to Identify SQL Injection Vulnerabilities","K. Zhang","Wayne State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1286","1288","This paper presents a machine learning classifier designed to identify SQL injection vulnerabilities in PHP code. Both classical and deep learning based machine learning algorithms were used to train and evaluate classifier models using input validation and sanitization features extracted from source code files. On ten-fold cross validations a model trained using Convolutional Neural Network(CNN) achieved the highest precision (95.4%), while a model based on Multilayer Perceptron(MLP) achieved the highest recall (63.7%) and the highest f-measure (0.746).","","","10.1109/ASE.2019.00164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952467","Deep learning;prediction model;SQL injection;vulnerability","","","","","","18","","","","","IEEE","IEEE Conferences"
"Test Automation and Its Limitations: A Case Study","A. Sung; S. Kim; Y. Kim; Y. Jang; J. Kim","Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1208","1209","Modern embedded systems are increasingly complex and contain multiple software layers from BSP (Board Support Packages) to OS to middleware to AI (Artificial Intelligence) algorithms like perception and voice recognition. Integrations of inter-layer and intra-layer in embedded systems provide dedicated services such as taking a picture or movie-streaming. Accordingly, it gets more complicated to find out the root cause of a system failure. This industrial proposal describes a difficulty of testing embedded systems, and presents a case study in terms of integration testing.","","","10.1109/ASE.2019.00139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952292","embedded system, software layer, integration test, test automation","","","","","","19","","","","","IEEE","IEEE Conferences"
"PHANTA: Diversified Test Code Quality Measurement for Modern Software Development","S. Tokumoto; K. Takayama","Fujitsu Laboratories Ltd.; Fujitsu Laboratories Ltd.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1206","1207","Test code is becoming more essential to the modern software development process. However, practitioners often pay inadequate attention to key aspects of test code quality, such as bug detectability, maintainability and speed. Existing tools also typically report a single test code quality measure, such as code coverage, rather than a diversified set of metrics. To measure and visualize quality of test code in a comprehensive fashion, we developed an integrated test code analysis tool called Phanta. In this show case, we posit that the enhancement of test code quality is key to modernizing software development, and show how Phanta's techniques measure the quality using mutation analysis, test code clone detection, and so on. Further, we present an industrial case study where Phanta was applied to analyze test code in a real Fujitsu project, and share lessons learned from the case study.","","","10.1109/ASE.2019.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952538","Software Testing;Test Code;Mutation Testing","","","","","","6","","","","","IEEE","IEEE Conferences"
"Enabling Continuous Improvement of a Continuous Integration Process","C. Vassallo","University of Zurich","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1246","1249","Continuous Integration (CI) is a widely-adopted software engineering practice. Despite its undisputed benefits, like higher software quality and improved developer productivity, mastering CI is not easy. Among the several barriers when transitioning to CI, developers need to face a new type of software failures (i.e., build failures) that requires them to understand complex build logs. Even when a team has successfully introduced a CI culture, living up to its principles and improving the CI practice are also challenging. In my research, I want to provide developers with the right support for establishing CI and the proper recommendations for continuously improving their CI process.","","","10.1109/ASE.2019.00151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952505","Continuous Integration, Build Failures, Anti patterns, Best Practices","","","","","","26","","","","","IEEE","IEEE Conferences"
"Better Development of Safety Critical Systems: Chinese High Speed Railway System Development Experience Report","Z. Wu; J. Liu; X. Chen","East China Normal University; East China Normal University; R&D Institute, CASCO Signal Ltd.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1216","1217","Ensure the correctness of safety critical systems play a key role in the worldwide software engineering. Over the past years we have been helping CASCO Signal Ltd which is the Chinese biggest high speed railway company to develop high speed railway safety critical software. We have also contributed specific methods for developing better safety critical software, including a search-based model-driven software development approach which uses SysML diagram refinement method to construct SysML model and SAT solver to check the model. This talk aims at sharing the challenge of developing high speed railway safety critical system, what we learn from develop a safety critical software with a Chinese high speed railway company, and we use ZC subsystem as a case study to show the systematic model-driven safety critical software development method.","","","10.1109/ASE.2019.00143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952294","SysML;Formal Method;Model-Driven;SAT","","","","","","7","","","","","IEEE","IEEE Conferences"
"User Preference Aware Multimedia Pricing Model using Game Theory and Prospect Theory for Wireless Communications","K. M. Kattiyan Ramamoorthy","San Diego State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1265","1267","Providing user satisfaction is a major concern for on-demand multimedia service providers and Internet carriers in Wireless Communications. Traditionally, user satisfaction was measured objectively in terms of throughput and latency. Nowadays the user satisfaction is measured using subjective metrices such as Quality of Experience (QoE). Recently, Smart Media Pricing (SMP) was conceptualized to price the QoE rather than the binary data traffic in multimedia services. In this research, we have leveraged the SMP concept to chalk up a QoE-sensitive multimedia pricing framework to allot price, based on the user preference and multimedia quality achieved by the customer. We begin by defining the utility equations for the provider-carrier and the customer. Then we translate the profit maximizing interplay between the parties into a two-stage Stackelberg game. We model the user personal preference using Prelec weighting function which follows the postulates Prospect Theory (PT). An algorithm has been developed to implement the proposed pricing scheme and determine the Nash Equilibrium. Finally, the proposed smart pricing scheme was tested against the traditional pricing method and simulation results indicate a significant boost in the utility achieved by the mobile customers.","","","10.1109/ASE.2019.00157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952218","Network Economics;Game Theory;Prospect Theory;Quality of Experience (QoE);Smart Multimedia Pricing","","","","","","11","","","","","IEEE","IEEE Conferences"
"Ares: Inferring Error Specifications through Static Analysis","C. Li; M. Zhou; Z. Gu; M. Gu; H. Zhang","Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1174","1177","Misuse of APIs happens frequently due to misunderstanding of API semantics and lack of documentation. An important category of API-related defects is the error handling defects, which may result in security and reliability flaws. These defects can be detected with the help of static program analysis, provided that error specifications are known. The error specification of an API function indicates how the function can fail. Writing error specifications manually is time-consuming and tedious. Therefore, automatic inferring the error specification from API usage code is preferred. In this paper, we present Ares, a tool for automatic inferring error specifications for C code through static analysis. We employ multiple heuristics to identify error handling blocks and infer error specifications by analyzing the corresponding condition logic. Ares is evaluated on 19 real world projects, and the results reveal that Ares outperforms the state-of-the-art tool APEx by 37% in precision. Ares can also identify more error specifications than APEx. Moreover, the specifications inferred from Ares help find dozens of API-related bugs in well-known projects such as OpenSSL, among them 10 bugs are confirmed by developers. Video: https://youtu.be/nf1QnFAmu8Q. Repository: https://github.com/lc3412/Ares.","","","10.1109/ASE.2019.00130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952222","Error Handling;Error Specification;Static Analysis","","","","","","12","","","","","IEEE","IEEE Conferences"
"Empirical Study of Python Call Graph","L. Yu","Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1274","1276","In recent years, the extensive application of the Python language has made its analysis work more and more valuable. Many static analysis algorithms need to rely on the construction of call graphs. In this paper, we did a comparative empirical analysis of several widely used Python static call graph tools both quantitatively and qualitatively. Experiments show that the existing Python static call graph tools have a large difference in the construction effectiveness, and there is still room for improvement.","","","10.1109/ASE.2019.00160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952190","Python, call graph, empirical study, quantitative, qualitative","","","","","","13","","","","","IEEE","IEEE Conferences"
"Verifying Determinism in Sequential Programs","R. Mudduluru","University of Washington","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1271","1273","A nondeterministic program is difficult to test and debug. Nondeterminism occurs even in sequential programs: for example, iterating over the elements of a hash table can result in diverging test results. We have created a type system that can express whether a computation is deterministic, nondeterministic, or ordernondeterministic (like a set). While state-of-the-art nondeterminism detection tools unsoundly rely on observing run-time output, our approach soundly verifies determinism at compile time. Our implementation found previously-unknown nondeterminism errors in a 24,000 line program that had been heavily vetted by its developers.","","","10.1109/ASE.2019.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952328","nondeterminism, type system, verification, specification","","","","","","9","","","","","IEEE","IEEE Conferences"
"Grading-Based Test Suite Augmentation","J. Osei-Owusu; A. Astorga; L. Butler; T. Xie; G. Challen","University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; Peking University; Ministry of Education; University of Illinois at Urbana-Champaign","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","226","229","Enrollment in introductory programming (CS1) courses continues to surge and hundreds of CS1 students can produce thousands of submissions for a single problem, all requiring timely and accurate grading. One way that instructors can efficiently grade is to construct a custom instructor test suite that compares a student submission to a reference solution over randomly generated or hand-crafted inputs. However, such test suite is often insufficient, causing incorrect submissions to be marked as correct. To address this issue, we propose the Grasa (GRAding-based test Suite Augmentation) approach consisting of two techniques. Grasa first detects and clusters incorrect submissions by approximating their behavioral equivalence to each other. To augment the existing instructor test suite, Grasa generates a minimal set of additional tests that help detect the incorrect submissions. We evaluate our Grasa approach on a dataset of CS1 student submissions for three programming problems. Our preliminary results show that Grasa can effectively identify incorrect student submissions and minimally augment the instructor test suite.","","","10.1109/ASE.2019.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952332","programming education;testing;clustering","","","","","","14","","","","","IEEE","IEEE Conferences"
"Crowdsourced Report Generation via Bug Screenshot Understanding","S. Yu","Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1277","1279","Quality control is a challenge of crowdsourcing, especially in software testing. As some unprofessional workers involved, low-quality yieldings may hinder crowdsourced testing from satisfying requesters' requirements. Therefore, it is in demand to assist crowdworkers to raise bug report quality. In this paper, we propose a novel auxiliary method, namely CroReG, to generate crowdsourcing bug reports by analyzing bug screenshots uploaded by crowdworkers with image understanding techniques. The preliminary experiment results show that CroReG can effectively generate bug reports containing accurate screenshot captions and providing positive guidance for crowdworkers.","","","10.1109/ASE.2019.00161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952296","Crowdsourced Testing;Mobile App Testing;Bug Report Generation","","","","","","11","","","","","IEEE","IEEE Conferences"
"How Do API Selections Affect the Runtime Performance of Data Analytics Tasks?","Y. Tao; S. Tang; Y. Liu; Z. Xu; S. Qin","Shenzhen University; Shenzhen University; Southern University of Science and Technology; Shenzhen University; Teesside University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","665","668","As data volume and complexity grow at an unprecedented rate, the performance of data analytics programs is becoming a major concern for developers. We observed that developers sometimes use alternative data analytics APIs to improve program runtime performance while preserving functional equivalence. However, little is known on the characteristics and performance attributes of alternative data analytics APIs. In this paper, we propose a novel approach to extracting alternative implementations that invoke different data analytics APIs to solve the same tasks. A key appeal of our approach is that it exploits the comparative structures in Stack Overflow discussions to discover programming alternatives. We show that our approach is promising, as 86% of the extracted code pairs were validated as true alternative implementations. In over 20% of these pairs, the faster implementation was reported to achieve a 10x or more speedup over its slower alternative. We hope that our study offers a new perspective of API recommendation and motivates future research on optimizing data analytics programs.","","","10.1109/ASE.2019.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952224","API selection, data analytics, performance optimization, Stack Overflow","","","","","","11","","","","","IEEE","IEEE Conferences"
"mCUTE: A Model-Level Concolic Unit Testing Engine for UML State Machines","R. Ahmadi; K. Jahed; J. Dingel","Queen's University; Queen's University; Queen's University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1182","1185","Model Driven Engineering (MDE) techniques raise the level of abstraction at which developers construct software. However, modern cyber-physical systems are becoming more prevalent and complex and hence software models that represent the structure and behavior of such systems still tend to be large and complex. These models may have numerous if not infinite possible behaviors, with complex communications between their components. Appropriate software testing techniques to generate test cases with high coverage rate to put these systems to test at the model-level (without the need to understand the underlying code generator or refer to the generated code) are therefore important. Concolic testing, a hybrid testing technique that benefits from both concrete and symbolic execution, gains a high execution coverage and is used extensively in the industry for program testing but not for software models. In this paper, we present a novel technique and its tool mCUTE1, an open source 2 model-level concolic testing engine. We describe the implementation of our tool in the context of Papyrus-RT, an open source Model Driven Engineering (MDE) tool based on UML-RT, and report the results of validating our tool using a set of benchmark models.","","","10.1109/ASE.2019.00132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952438","Concolic Testing, MDE, State machines, Unit Testing, UML","","","","","","22","","","","","IEEE","IEEE Conferences"
"LIRAT: Layout and Image Recognition Driving Automated Mobile Testing of Cross-Platform","S. Yu; C. Fang; Y. Feng; W. Zhao; Z. Chen","Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1066","1069","The fragmentation issue spreads over multiple mobile platforms such as Android, iOS, mobile web, and WeChat, which hinders test scripts from running across platforms. To reduce the cost of adapting scripts for various platforms, some existing tools apply conventional computer vision techniques to replay the same script on multiple platforms. However, because these solutions can hardly identify dynamic or similar widgets. It becomes difficult for engineers to apply them in practice. In this paper, we present an image-driven tool, namely LIRAT, to record and replay test scripts cross platforms, solving the problem of test script cross-platform replay for the first time. LIRAT records screenshots and layouts of the widgets, and leverages image understanding techniques to locate them in the replay process. Based on accurate widget localization, LIRAT supports replaying test scripts across devices and platforms. We employed LIRAT to replay 25 scripts from 5 application across 8 Android devices and 2 iOS devices. The results show that LIRAT can replay 88% scripts on Android platforms and 60% on iOS platforms. The demo can be found at: https: //github.com/YSC9848/LIRAT","","","10.1109/ASE.2019.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952513","Cross-Platform Testing;Image Recognition;Record and Replay","","","","","","11","","","","","IEEE","IEEE Conferences"
"Automatic Generation of Graphical User Interface Prototypes from Unrestricted Natural Language Requirements","K. Kolthoff","Institute for Enterprise Systems (InES), University of Mannheim","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1234","1237","High-fidelity GUI prototyping provides a meaningful manner for illustrating the developers' understanding of the requirements formulated by the customer and can be used for productive discussions and clarification of requirements and expectations. However, high-fidelity prototypes are time-consuming and expensive to develop. Furthermore, the interpretation of requirements expressed in informal natural language is often error-prone due to ambiguities and misunderstandings. In this dissertation project, we will develop a methodology based on Natural Language Processing (NLP) for supporting GUI prototyping by automatically translating Natural Language Requirements (NLR) into a formal Domain-Specific Language (DSL) describing the GUI and its navigational schema. The generated DSL can be further translated into corresponding target platform prototypes and directly provided to the user for inspection. Most related systems stop after generating artifacts, however, we introduce an intelligent and automatic interaction mechanism that allows users to provide natural language feedback on generated prototypes in an iterative fashion, which accordingly will be translated into respective prototype changes.","","","10.1109/ASE.2019.00148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952477","Graphical;User;Interface;Automatic;GUI;Generation;Processing;Natural;Language;Requirements;Intelligent;Interaction;Prototyping","","","","","","29","","","","","IEEE","IEEE Conferences"
"SPrinter: A Static Checker for Finding Smart Pointer Errors in C++ Programs","X. Ma; J. Yan; Y. Li; J. Yan; J. Zhang","Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1122","1125","Smart pointers are widely used to prevent memory errors in modern C++ code. However, improper usage of smart pointers may also lead to common memory errors, which makes the code not as safe as expected. To avoid smart pointer errors as early as possible, we present a coding style checker to detect possible bad smart pointer usages during compile time, and notify programmers about bug-prone behaviors. The evaluation indicates that the currently available state-of-the-art static code checkers can only detect 25 out of 116 manually inserted errors, while our tool can detect all these errors. And we also found 521 bugs among 8 open source projects with only 4 false positives.","","","10.1109/ASE.2019.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952230","C++ Smart Pointer;Memory Error;Coding Styles","","","","","","12","","","","","IEEE","IEEE Conferences"
"PMExec: An Execution Engine of Partial UML-RT Models","M. Bagherzadeh; K. Jahed; N. Kahani; J. Dingel","Queen's University; Queen's University; Queen's University; Queen's University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1178","1181","This paper presents PMExec, a tool that supports the execution of partial UML-RT models. To this end, the tool implements the following steps: static analysis, automatic refinement, and input-driven execution. The static analysis that respects the execution semantics of UML-RT models is used to detect problematic model elements, i.e., elements that cause problems during execution due to the partiality. Then, the models are refined automatically using model transformation techniques, which mostly add decision points where missing information can be supplied. Third, the refined models are executed, and when the execution reaches the decision points, input required to continue the execution is obtained either interactively or from a script that captures how to deal with partial elements. We have evaluated PMExec using several use-cases that show that the static analysis, refinement, and application of user input can be carried out with reasonable performance, and that the overhead of approach is manageable. https://youtu.be/BRKsselcMnc Note: Interested readers can refer to [1] for a thorough discussion and evaluation of this work.","","","10.1109/ASE.2019.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952369","MDD;Partial Models;Execution;Debugging;Model level debugging;Model execution","","","","","","12","","","","","IEEE","IEEE Conferences"
"TestCov: Robust Test-Suite Execution and Coverage Measurement","D. Beyer; T. Lemberger","LMU Munich; LMU Munich","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1074","1077","We present TestCov, a tool for robust test-suite execution and test-coverage measurement on C programs. TestCov executes program tests in isolated containers to ensure system integrity and reliable resource control. The tool provides coverage statistics per test and for the whole test suite. TestCov uses the simple, XML -based exchange format for test-suite specifications that was established as standard by Test-Comp. TestCov has been successfully used in Test-Comp '19 to execute almost 9 million tests on 1720 different programs. The source code of TestCov is released under the open-source license Apache 2.0 and available at https://gitlab.com/sosy-lab/software/test-suite-validator. A full artifact, including a demonstration video, is available at https://doi.org/10.5281/zenodo.3418726.","","","10.1109/ASE.2019.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952265","Test Execution, Coverage, Test-Suite Reduction","","","","","","13","","","","","IEEE","IEEE Conferences"
"Improving Patch Quality by Enhancing Key Components of Automatic Program Repair","M. Soto","Carnegie Mellon University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1230","1233","The error repair process in software systems is, historically, a resource-consuming task that relies heavily in developer manual effort. Automatic program repair approaches enable the repair of software with minimum human interaction, therefore, mitigating the burden from developers. However, a problem automatically generated patches commonly suffer is generating low-quality patches (which overfit to one program specification, thus not generalizing to an independent oracle evaluation). This work proposes a set of mechanisms to increase the quality of plausible patches including an analysis of test suite behavior and their key characteristics for automatic program repair, analyzing developer behavior to inform the mutation operator selection distribution, and a study of patch diversity as a means to create consolidated higher quality fixes.","","","10.1109/ASE.2019.00147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952342","Automatic Program Repair, Patch Quality","","","","","","19","","","","","IEEE","IEEE Conferences"
"PTracer: A Linux Kernel Patch Trace Bot","Y. Wen; J. Cao; S. Cheng","ZTE Corporation; ZTE Corporation; ZTE Corporation","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1210","1211","We present PTracer, a Linux kernel patch trace bot based on an improved PatchNet. PTracer continuously monitors new patches in the git repository of the mainline Linux kernel, filters out unconcerned ones, classifies the rest as bug-fixing or non bug-fixing patches, and reports bug-fixing patches to the kernel experts of commercial operating systems. We use the patches in February 2019 of the mainline Linux kernel to perform the test. As a result, PTracer recommended 151 patches to CGEL kernel experts out of 5,142, and 102 of which were accepted. PTracer has been successfully applied to a commercial operating system and has the advantages of improving software quality and saving labor cost.","","","10.1109/ASE.2019.00140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952485","Linux kernel;patch identification;trace bot","","","","","","7","","","","","IEEE","IEEE Conferences"
"AutoFocus: Interpreting Attention-Based Neural Networks by Code Perturbation","N. D. Q. Bui; Y. Yu; L. Jiang","Singapore Management University; The Open University, UK; Singapore Management University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","38","41","Despite being adopted in software engineering tasks, deep neural networks are treated mostly as a black box due to the difficulty in interpreting how the networks infer the outputs from the inputs. To address this problem, we propose AutoFocus, an automated approach for rating and visualizing the importance of input elements based on their effects on the outputs of the networks. The approach is built on our hypotheses that (1) attention mechanisms incorporated into neural networks can generate discriminative scores for various input elements and (2) the discriminative scores reflect the effects of input elements on the outputs of the networks. This paper verifies the hypotheses by applying AutoFocus on the task of algorithm classification (i.e., given a program source code as input, determine the algorithm implemented by the program). AutoFocus identifies and perturbs code elements in a program systematically, and quantifies the effects of the perturbed elements on the network's classification results. Based on evaluation on more than 1000 programs for 10 different sorting algorithms, we observe that the attention scores are highly correlated to the effects of the perturbed code elements. Such a correlation provides a strong basis for the uses of attention scores to interpret the relations between code elements and the algorithm classification results of a neural network, and we believe that visualizing code elements in an input program ranked according to their attention scores can facilitate faster program comprehension with reduced code.","","","10.1109/ASE.2019.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952269","attention mechanisms, neural networks, algorithm classification, interpretability, explainability, code perturbation, program comprehension","","","","","","17","","","","","IEEE","IEEE Conferences"
"VeriAbs : Verification by Abstraction and Test Generation","M. Afzal; A. Asia; A. Chauhan; B. Chimdyalwar; P. Darke; A. Datar; S. Kumar; R. Venkatesh","Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1138","1141","Verification of programs continues to be a challenge and no single known technique succeeds on all programs. In this paper we present VeriAbs, a reachability verifier for C programs that incorporates a portfolio of techniques implemented as four strategies, where each strategy is a set of techniques applied in a specific sequence. It selects a strategy based on the kind of loops in the program. We analysed the effectiveness of the implemented strategies on the 3831 verification tasks from the ReachSafety category of the 8th International Competition on Software Verification (SV-COMP) 2019 and found that although classic techniques - explicit state model checking and bounded model checking, succeed on a majority of the programs, a wide range of further techniques are required to analyse the rest. A screencast of the tool is available at https://youtu.be/Hzh3PPiODwk.","","","10.1109/ASE.2019.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952452","Software Verification;Strategy Selection;Portfolio Verifier;Loop Abstraction;Array Abstraction;Bounded Model Checking;Fuzz Testing;Loop Invariant Generation;Value Analysis","","","","","","27","","","","","IEEE","IEEE Conferences"
