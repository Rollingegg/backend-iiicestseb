"Document Title","Authors","Author Affiliations","Publication Title","Date Added To Xplore","Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBNs","DOI","Funding Information","PDF Link","Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms","Article Citation Count","Reference Count","License","Online Date","Issue Date","Meeting Date","Publisher","Document Identifier"
"Combining Spectrum-Based Fault Localization and Statistical Debugging: An Empirical Study","J. Jiang; R. Wang; Y. Xiong; X. Chen; L. Zhang","Peking University; Peking University; Peking University; Sun Yat-sen University; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","502","514","Program debugging is a time-consuming task, and researchers have proposed different kinds of automatic fault localization techniques to mitigate the burden of manual debugging. Among these techniques, two popular families are spectrum-based fault localization (SBFL) and statistical debugging (SD), both localizing faults by collecting statistical information at runtime. Though the ideas are similar, the two families have been developed independently and their combinations have not been systematically explored. In this paper we perform a systematical empirical study on the combination of SBFL and SD. We first build a unified model of the two techniques, and systematically explore four types of variations, different predicates, different risk evaluation formulas, different granularities of data collection, and different methods of combining suspicious scores. Our study leads to several findings. First, most of the effectiveness of the combined approach contributed by a simple type of predicates: branch conditions. Second, the risk evaluation formulas of SBFL significantly outperform that of SD. Third, fine-grained data collection significantly outperforms coarse-grained data collection with a little extra execution overhead. Fourth, a linear combination of SBFL and SD predicates outperforms both individual approaches. According to our empirical study, we propose a new fault localization approach, PREDFL (Predicate-based Fault Localization), with the best configuration for each dimension under the unified model. Then, we explore its complementarity to existing techniques by integrating PREDFL with a state-of-the-art fault localization framework. The experimental results show that PREDFL can further improve the effectiveness of state-of-the-art fault localization techniques. More concretely, integrating PREDFL results in an up to 20.8% improvement w.r.t the faults successfully located at Top-1, which reveals that PREDFL complements existing techniques.","","","10.1109/ASE.2019.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952344","Software engineering, Fault localization, Program debugging","","","","","","79","","","","","IEEE","IEEE Conferences"
"Logzip: Extracting Hidden Structures via Iterative Clustering for Log Compression","J. Liu; J. Zhu; S. He; P. He; Z. Zheng; M. R. Lyu","Sun Yat-Sen University & The Chinese University of Hong Kong; Huawei Noahâ€™s Ark Lab, China; The Chinese University of Hong Kong; ETH Zurich; Sun Yat-Sen University; The Chinese University of Hong Kong","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","863","873","System logs record detailed runtime information of software systems and are used as the main data source for many tasks around software engineering. As modern software systems are evolving into large scale and complex structures, logs have become one type of fast-growing big data in industry. In particular, such logs often need to be stored for a long time in practice (e.g., a year), in order to analyze recurrent problems or track security issues. However, archiving logs consumes a large amount of storage space and computing resources, which in turn incurs high operational cost. Data compression is essential to reduce the cost of log storage. Traditional compression tools (e.g., gzip) work well for general texts, but are not tailed for system logs. In this paper, we propose a novel and effective log compression method, namely logzip. Logzip is capable of extracting hidden structures from raw logs via fast iterative clustering and further generating coherent intermediate representations that allow for more effective compression. We evaluate logzip on five large log datasets of different system types, with a total of 63.6 GB in size. The results show that logzip can save about half of the storage space on average over traditional compression tools. Meanwhile, the design of logzip is highly parallel and only incurs negligible overhead. In addition, we share our industrial experience of applying logzip to Huawei's real products.","","","10.1109/ASE.2019.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952406","logs;structure extraction;log compression;log management;iterative clustering","","","","","","49","","","","","IEEE","IEEE Conferences"